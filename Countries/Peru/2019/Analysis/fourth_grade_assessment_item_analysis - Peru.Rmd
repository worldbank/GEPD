---
title: "Item Analysis of GEPD 4th Grade Knowledge Module - Peru"
author: Brian Stacy
date: "`r Sys.Date()`"
output:
  html_document: 
    toc: true
    theme: readable

---


<style type="text/css">

body{ /* Normal  */
      font-size: 16px;
  }
td {  /* Table  */
  font-size: 14px;
}
caption {  /* Caption  */
  font-color: black;
  font-weight: bold;
  font-size: 20px;
}
</style>




# Abstract

Using GEPD data from Peru, this paper examines the psychometric properties of the 4th grade student assessment module.  We produce summary statistics of the fraction correct overall, by subdomain, and at the item level.  We examine the test reliability of our domains.  We then plot estimated probabilities of a correct responses on our six math items that are aligned with at least a 4th grade curriculum on the number of items correct to get an appropriate cutscore.

Future work will do a similar exercise with literacy.







```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#===============
# LOAD PACKAGES
#===============
library(tidyverse)
library(haven)
library(mirt)
library(equateIRT)
library(skimr)
library(DT)
library(knitr)
library(kableExtra)
library(captioner)
library(ggcorrplot)
library(plotly)
library(psych)
library(crosstalk)
library(RColorBrewer)
library(data.table)
library(ggridges)
library(Hmisc)
library(psych) # For Cronbach's alpha
library(lavaan) # For Confirmatory Factor Analysis
library(spatstat)
library(ggpubr)
#===============
# GET DATA
#===============

#set directory:
work_dir<-"C:/Users/wb469649/OneDrive - WBG/4th Grade Assessment - Dashboard - To Share/"

```





```{r echo=FALSE}

#===============
# GET DATA
#===============

#Create function to save metadata for each question in each module
#The attr function retrieves metadata imported by haven. E.g. attr(school_dta$m1s0q2_code, "label")
makeVlist <- function(dta) { 
  varlabels <- sapply(dta, function(x) attr(x,"label"))
  vallabels <- sapply(dta, function(x) attr(x,"labels"))
  tibble(name = names(varlabels),
         varlabel = varlabels, vallabel = vallabels) 
}


#load data
load(file=paste(work_dir, 'Data/dashboard_4th_grade_assessment_data_peru.RData', sep=""))
#Load original sample of schools
currentDate<-c("2019-07-22")
sample_frame_name <- paste("C:/Users/WB469649/WBG/Ezequiel Molina - Dashboard (Team Folder)/Country_Work/Peru/2019/Data/sampling/school_sample_",currentDate,".RData", sep="")

load(sample_frame_name)
#function to create zero/one variables  
bin_var <- function(var, val) {
  case_when(
    var==val  ~ 1,
    var!=val   ~ 0,
    is.na(var) ~ as.numeric(NA))
}

bin_var_NA0 <- function(var, val) {
  case_when(
    var==val  ~ 1,
    var!=val   ~ 0,
    is.na(var) ~ 0)
}

#create function to make titles in figures nice
wrapper <- function(x, ...) 
{
  paste(strwrap(x, ...), collapse = "\n")
}

#produce caption for tables/figures
  tab_num<-captioner(prefix="Table")
  fig_num<-captioner(prefix="Figure")

  
#get weights from original sample
assess_4th_grade_weights <- assess_4th_grade_anon %>%
  group_by(school_code) %>%
  mutate(total_sampled=n()) %>%
  ungroup() %>%
  mutate(codigo.modular=as.numeric(school_code)) %>%
  left_join(data_set_updated) %>%
  mutate( school_ipw=weights*total_1st/total_sampled)  %>%
  mutate(school_ipw=if_else(is.na(school_ipw), median(school_ipw, na.rm=T), school_ipw)) %>%
  select(colnames(assess_4th_grade_anon), school_ipw, total_sampled, departamento)
  
assess_4th_grade_weight_vec <- assess_4th_grade_weights$school_ipw
 


#add function to produce weighted summary stats
skim_with( numeric = list( mean = ~ wtd.mean(.,  w=school_ipw, na.rm=TRUE),
                                     sd = ~ sqrt(wtd.var(.,  weights=school_ipw, na.rm=TRUE)),
                                     p25 = ~ (wtd.quantile(., probs=c(0.25),  weights=school_ipw, na.rm=TRUE)),
                                     p50 = ~ (wtd.quantile(., probs=c(0.5), weights=school_ipw, na.rm=TRUE)),
                                     p75 = ~ (wtd.quantile(., probs=c(0.75), weights=school_ipw, na.rm=TRUE)),
                                     complete_count= ~ sum(!is.na(.))))



```

# Summary Statistics of Data
Before estimating the model, we begin by examining summary statistics and missing values in our item response data.  To begin, we will show summary statistics of the fraction correct on the literacy, and math sections of the examination, as well as the fraction correct on broad sub-domains.  

The sub-domains for the literacy section are:

* Letter Identification
*	Word Recognition
*	Reading Comprehension Story 

The sub-domains for the math section are:

*	Number Sense
*	Arithmetic
*	Word Problem
*	Sequences

    
```{r sumstats_domains, echo=FALSE, warning=FALSE}

#rename a few variables to be consistent with sub_domain tags
assess_4th_grade_weights <- assess_4th_grade_weights %>%
  mutate(m8saq2_letters=m8saq2_id,
         m8saq3_words=m8saq3_id,
         m8saq4_words=m8saq4_id,
         m8saq5_comprehension=m8saq5_story,
         m8saq6_comprehension=m8saq6_story,
         m8saq7_comprehension=m8saq7_word_choice
         )

#score each sub-domain
sub_domains <- c('letters','words','comprehension', 
                 'number_sense','arithmetic','word_problem', 'sequences')

#create function to score each sub-domain
sub_domain_scorer <- function(subdomain) {
     rowMeans(assess_4th_grade_weights[grep(x=colnames(assess_4th_grade_weights), 
                                              pattern=subdomain)], na.rm=TRUE)
}

assess_4th_grade_domains <- cbind(assess_4th_grade_weights, setNames(lapply(sub_domains, sub_domain_scorer),sub_domains))

assess_4th_grade_domains <-assess_4th_grade_domains %>%
  select( student_knowledge,
          literacy_student_knowledge, letters,words,comprehension,
          math_student_knowledge, number_sense,arithmetic,word_problem, sequences
)


name<-c('student_knowledge',
        'literacy_student_knowledge', 'letters','words','comprehension', 
        'math_student_knowledge', 'number_sense','arithmetic','word_problem', 'sequences')
varlabel<-c('Fraction correct overall',
            'Fraction correct Literacy', 'Letter Identification','Word Recognition','Reading Comprehension Story',
            'Fraction correct Numeracy', 'Number Sense','Arithmetic','Word Problem', 'Sequences')

assess_4th_grade_domains_metadata <- cbind.data.frame(name, varlabel)


#language
  school_ipw <- assess_4th_grade_weight_vec
 sumstats_assess_4th_grade_domains_df<-skim(assess_4th_grade_domains) %>%
     dplyr::select(-level, -type, -value) %>%
     spread(stat, formatted) %>%
     dplyr::select(variable, mean, sd, p0, p25, p50, p75, p100, complete, missing, hist) 

  #add variable label
  sumstats_assess_4th_grade_domains_df <- sumstats_assess_4th_grade_domains_df %>%
      mutate(name=variable) %>%
      left_join(assess_4th_grade_domains_metadata) %>%
      dplyr::select(variable, varlabel, mean, sd, p0, p25, p50, p75, p100, complete, missing, hist) %>%
      arrange(factor(variable, levels=name))
  
  
  #produce caption for table
  assess_4th_grade_sumstats_domain_cap<-tab_num(name="assess_4th_grade_stats_domain", caption="Summary Statistics of Fraction Correct on assess_4th_grade Assessment Domains for 1st Graders")
  
  #Produce table
  sumstats_assess_4th_grade_domains_df %>%
    kable(caption=assess_4th_grade_sumstats_domain_cap,
          col.names =c("Item", "Label", "Mean", "Std Dev","Min", "25th Percentile", "Median", "75th Percentile", "Max", "# Complete Cases", "# Missing Cases", "Histogram")
) %>%
    kable_styling(bootstrap_options = c("striped", "hover"),
                  fixed_thead = T,
                  ) %>%
  pack_rows("Overall", 1,1) %>%
  pack_rows("Literacy", 2,5) %>%
  pack_rows("Math", 6,10) %>%
    footnote(general="Summary table shows weighted summary statistics from 4th Grade assessment.")
 

```

## Item Level Summary Statistics

Next, we display summary statistics at the item level for our  assessment.  

```{r sumstats, echo=FALSE, message=FALSE, warning=FALSE}

#get list of items for each domain
lit_items<-colnames(assess_4th_grade_weights[,str_detect(
  colnames(assess_4th_grade_weights), "id|story|word_choice")])

math_items<-colnames(assess_4th_grade_weights[,str_detect(
  colnames(assess_4th_grade_weights), "number_sense|arithmetic|word_problem|sequences")])


assess_4th_grade_items <-assess_4th_grade_weights %>%
  select(lit_items, math_items)

#compute summary stats

 sumstats_assess_4th_grade_df<-skim(assess_4th_grade_items) %>%
     dplyr::select(-level, -type, -value) %>%
     spread(stat, formatted) %>%
     dplyr::select(variable, mean, sd, p0, p25, p50, p75, p100, complete, missing, hist) 
        

  #add variable label
  sumstats_assess_4th_grade_df <- sumstats_assess_4th_grade_df %>%
      mutate(name=variable) %>%
      left_join(assess_4th_grade_metadta) %>%
      dplyr::select(variable, varlabel, mean, sd, p0, p25, p50, p75, p100, complete, missing, hist) %>%
      arrange(factor(variable, levels=c(lit_items, math_items)))

  #produce caption for table
  assess_4th_grade_sumstats_cap<-tab_num(name="assess_4th_grade_sumstats_cap", caption="Summary Statistics of 4th Grade Assessment Items")
  
  #Produce table
  sumstats_assess_4th_grade_df %>%
    kable(caption=assess_4th_grade_sumstats_cap,
          col.names =c("Item", "Label", "Mean", "Std Dev","Min", "25th Percentile", "Median", "75th Percentile", "Max", "# Complete Cases", "# Missing Cases", "Histogram")
) %>%
    kable_styling(bootstrap_options = c("striped", "hover"),
                  fixed_thead = T,
                  ) %>%
  pack_rows("Literacy", 1,6) %>%
  pack_rows("Numeracy", 7,21) %>%
  footnote(general="Summary table shows weighted summary statistics from 4th grade assessment.")
 
```

## Inter-Item Correlations

Next we display inter-item correlations for our 1st grade assessment.  

```{r iic, echo=FALSE, message=FALSE, warning=FALSE, out.width = "70%"}
assess_4th_grade_corr_plot <- round(cor(assess_4th_grade_items , use="complete.obs"), 2)
      
        assess_4th_grade_corr_cap<-fig_num(name="assess_4th_grade_corr_cap", caption="Correlation Between assess_4th_grade Items")

      pcorr<- ggcorrplot(assess_4th_grade_corr_plot,
                         outline.color = "white",
                         type="full",
                         ggtheme = theme_bw(),
                         colors = c("#F8696B", "#FFEB84", "#63BE7B"),
                         legend.title = "Correlation",
                         title = assess_4th_grade_corr_cap) + 
        theme(
          text = element_text(size = 16),
        )
      
      m <- list(
         l = 50,
         r = 50,
         b = 100,
         t = 100,
         pad = 4
        )
      ggplotly(pcorr,
               width = 1000, height = 1000 ) %>%
          layout(autosize = F,  margin = m)

```

# Reliability and Internal Consistency


In Psychometrics, internal consistency is an estimate of test reliability.
Cronbach's Alpha (and other internal consistency coefficients) can take 
 values between 0 and 1, being tests more consistent as the value of this
 coefficient approaches to 1.

 In addition to the internal consistency coefficient for a construct, internal
 consistency analyses also include item level statistics of internal 
 consistency and item discrimination. You will notice in the output of the
 alpha() function three additional data frames: Reliability if an item is 
 dropped, Item statistics, and Non missing response frequency for each item. 
 We are interested in the first two data frames.

 In the case of the data frame "Reliability if an item is dropped", we
 need to check what happens with the overall Cronbach's alpha reliability
 when a given item is excluded from the analysis. This analysis allows
 us to identify inconsistent items when Cronbach's Alpha increases once
 a given item is excluded. This information will be shown in the first
 column of that data frame.

 In the case of the data frame "Item Statistics", we want to identify the
 item correlation with the construct observed total score when the item is
 excluded from that total score. Ideally, we want items with a positive 
 correlation between each item and the total score, otherwise that item is 
 probably not measuring the same construct as the others, does not correctly 
 discriminate among examinees, or has a problem in either its content 
 or scoring  procedure. From this data frame, we are interested in the 
 fifth column titled "r.drop".


 Internal consistency for literacy items.
 Cronbach's alpha = 0.80. Good reliability
 
 For each of our constructs, we report: Cronbach's alpha for the whole test, Cronbach's alpha increase or decrease when a given item is removed, and item-total construct score correlation (which is a CTT estimate of item discrimination).

```{r echo=FALSE, message=FALSE, warning=FALSE}

## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ##
## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ##
# 1. Internal consistency and Item-Construct correlation with Construct score
#    excluding the item.
## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ##
## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ##

# The function alpha() included in the "psych" package estimates the Cronbach's
# Alpha coefficient and item level statistics linked to CTT reliability and 
# CTT item discrimination. 

# IMPORTANT: We psychologists usually calculate Cronbach Alpha separately for
# each one of the constructs measured by a test. Thus, you will notice that I
# running the function alpha() three times with different column vectors from
# my data set.

# In Psychometrics, internal consistency is an estimate of test reliability.
# Cronbach's Alpha (and other internal consistency coefficients) can take 
# values between 0 and 1, being tests more consistent as the value of this
# coefficient approaches to 1.

# In addition to the internal consistency coefficient for a construct, internal
# consistency analyses also include item level statistics of internal 
# consistency and item discrimination. You will notice in the output of the
# alpha() function three additional data frames: Reliability if an item is 
# dropped, Item statistics, and Non missing response frequency for each item. 
# We are interested in the first two data frames.

# In the case of the data frame "Reliability if an item is dropped", we
# need to check what happens with the overall Cronbach's alpha reliability
# when a given item is excluded from the analysis. This analysis allows
# us to identify inconsistent items when Cronbach's Alpha increases once
# a given item is excluded. This information will be shown in the first
# column of that data frame.

# In the case of the data frame "Item Statistics", we want to identify the
# item correlation with the construct observed total score when the item is
# excluded from that total score. Ideally, we want items with a positive 
# correlation between each item and the total score, otherwise that item is 
# probably not measuring the same construct as the others, does not correctly 
# discriminate among examinees, or has a problem in either its content 
# or scoring  procedure. From this data frame, we are interested in the 
# fifth column titled "r.drop".


# Internal consistency for literacy items.
# Cronbach's alpha = 0.80. Good reliability
# Notice that removing the item "lit_i1_11" would increase Cronbach's Alpha
# to 0.81. Although positive, this item presents the lowest correlation with
# the construct observed total score.

#write a function to compute alpha and then save as a dataframe
cronbach_table <- function(subdom) {
  subdomain <- alpha(assess_4th_grade_weights[grepl(x=colnames(assess_4th_grade_weights), pattern=subdom)])
  
  data.frame(subdomain$total[1], 
           subdomain$alpha.drop[1], 
           subdomain$item.stats[5])
}

#now apply this function to all of our sub-domains
literacy <- cronbach_table('id|story|word_choice')
# letters <- cronbach_table('letters')
# words <- cronbach_table('words')
# comprehension <- cronbach_table('comprehension')

math <- cronbach_table('number_sense|arithmetic|word_problem|sequences')
# number_sense <- cronbach_table('number_sense')
arithmetic <- cronbach_table('arithmetic')
# word_problem <- cronbach_table('word_problem')
# sequences <- cronbach_table('sequences')

alpha_table <- rbind(literacy, #vocabn, comprehension, letters, words, sentence, print,
                     math #produce_set, number_ident, number_compare, simple_add,)
                    )

assess_4th_grade_alpha_data_cap<-tab_num(name="assess_4th_grade_alpha_data_cap", caption="Internal Consistency for 4th Grade items")

kable(alpha_table,
      caption = assess_4th_grade_alpha_data_cap,
      col.names = c('Cronbach alpha for the whole test', 'Cronbach alpha increase or decrease when a given item is removed', 'Item-total construct score correlation' )) %>%
  pack_rows("Literacy", 1,6) %>%
  pack_rows("Math", 7,21) %>%
    kable_styling(bootstrap_options = c("striped", "hover"),
                  fixed_thead = T,
                  )
```





# IRT Parameter Estimates from 2PL Model



```{r irt_model, echo=FALSE, warning=TRUE}

#create matrix with  just item responses
math <- assess_4th_grade_anon %>%
  select(contains('m8sb')) %>%
  mutate(m8sbq1_number_sense=as.numeric(m8sbq1_number_sense==1))

language <- assess_4th_grade_anon %>%
  select(contains('m8sa')) %>%
  mutate(m8saq2_id=as.numeric(m8saq2_id==1),
         m8saq3_id=as.numeric(m8saq3_id==1),
         m8saq4_id=as.numeric(m8saq4_id==1))

#Estimate IRT parameters ignoring missing values
irt_math_2PL <- mirt(math, 1, itemtype='2PL', optimizer='NR', SE=T, technical=list(removeEmptyRows=TRUE))
rownames_to_column(as.data.frame(coef(irt_math_2PL, IRTpars=TRUE, as.data.frame=TRUE))) %>%
  filter(!grepl(".g|.u", rowname)) %>%
  separate(rowname, c('variable', 'parameter'), sep="\\.") %>%
  mutate(parameter=case_when(
    parameter=="a" ~ 'discrimination',
    parameter=="b" ~ 'difficulty'
  )) %>%
  pivot_wider(names_from = parameter, values_from=c('par', 'CI_2.5', 'CI_97.5')) %>%
  left_join(assess_4th_grade_metadta, by=c('variable'='name')) %>%
  dplyr::select(variable, varlabel, par_discrimination, CI_2.5_discrimination, CI_97.5_discrimination, par_difficulty, CI_2.5_difficulty, CI_97.5_difficulty) %>%
  kable() %>%
  kable_styling()

irt_lang_2PL<- mirt(language, 1, itemtype='2PL',optimizer='NR',  SE=T, technical=list(removeEmptyRows=TRUE))
rownames_to_column(as.data.frame(coef(irt_lang_2PL, IRTpars=TRUE, as.data.frame=TRUE))) %>%
  filter(!grepl(".g|.u", rowname)) %>%
  separate(rowname, c('variable', 'parameter'), sep="\\.") %>%
  mutate(parameter=case_when(
    parameter=="a" ~ 'discrimination',
    parameter=="b" ~ 'difficulty'
  )) %>%
  pivot_wider(names_from = parameter, values_from=c('par', 'CI_2.5', 'CI_97.5')) %>%
  left_join(assess_4th_grade_metadta,by=c('variable'='name')) %>%
  dplyr::select(variable, varlabel, par_discrimination, CI_2.5_discrimination, CI_97.5_discrimination, par_difficulty, CI_2.5_difficulty, CI_97.5_difficulty) %>%
  kable() %>%
  kable_styling()





```

# Cut Score for Math

A set of experts from UIS reviewed the SDI 4th grade math test. According to the experts, items 3C, 3F, 3I, 5, and 6 are aligned with the skills expected in 4th grade. Item 3G is aligned to the content of 5th grade. The remaining items are either aligned with skills in earlier grades or are measuring skills not covered in the GPF.

We will take the following approach to assigning a cut score for our math assessment:

*	Estimate ability levels for all Peru examinees using all math items in the SDI test.
*	Identify the ability level to the probability of correctly answering half of the aligned items.
* Translate that ability level to the closest score in the actual test (maybe through a linear scatterplot that shows the best fitting line).



```{r math_cut_score, echo=FALSE}

#estimate factor scores from models
lang_assess_scores<-data.frame(fscores(irt_lang_2PL, method='EAP', response.pattern = language))

math_assess_scores<-data.frame(fscores(irt_math_2PL, method='EAP', response.pattern = math))

# Get number correct and theta
Theta <- math_assess_scores$F1
math2 <- math %>%
  mutate(m8sbq1_number_sense=m8sbq1_number_sense*3)
num_correct <- rowSums(math2, na.rm=T)
#####################################################
# get probabiliy of correct response for these items
#####################################################

#items 3C
extr.3c <- extract.item(irt_math_2PL, 4)
traceline <- probtrace(extr.3c, Theta)

prob_3c <- data.frame(traceline, Theta, num_correct) %>%
  mutate(prob_correct=P.1,
         item='3c',
         id=row_number()) %>%
  select(-P.0, -P.1)


#items 3F
extr.3f <- extract.item(irt_math_2PL, 7)
traceline <- probtrace(extr.3f, Theta)

prob_3f <- data.frame(traceline, Theta, num_correct) %>%
  mutate(prob_correct=P.1,
         item='3f',
         id=row_number()) %>%
  select(-P.0, -P.1)
#items 3I
extr.3i <- extract.item(irt_math_2PL, 10)
traceline <- probtrace(extr.3i, Theta)

prob_3i <- data.frame(traceline, Theta, num_correct) %>%
  mutate(prob_correct=P.1,
         item='3i',
         id=row_number()) %>%
  select(-P.0, -P.1)
#items 5
extr.5 <- extract.item(irt_math_2PL, 13)
traceline <- probtrace(extr.5, Theta)

prob_5 <- data.frame(traceline, Theta, num_correct) %>%
  mutate(prob_correct=P.1,
         item='5',
         id=row_number()) %>%
  select(-P.0, -P.1)

#items 6
extr.6 <- extract.item(irt_math_2PL, 14)
traceline <- probtrace(extr.6, Theta)

prob_6 <- data.frame(traceline, Theta, num_correct) %>%
  mutate(prob_correct=P.1,
         item='6',
         id=row_number()) %>%
  select(-P.0, -P.1)
#items 3G
extr.3g <- extract.item(irt_math_2PL, 8)
traceline <- probtrace(extr.3g, Theta)

prob_3g <- data.frame(traceline, Theta, num_correct) %>%
  mutate(prob_correct=P.1,
         item='3g',
         id=row_number()) %>%
  select(-P.0, -P.1)



probs <- rbind(prob_3c, prob_3f, prob_3i,
               prob_5, prob_6, prob_3g)

#calculate average
prob_avg <- probs %>%
  group_by(id) %>%
  summarise(prob_correct=mean(prob_correct),
            num_correct=mean(num_correct),
            Theta=mean(Theta)) %>%
  mutate(item='Average')

probs<-probs %>%
  bind_rows(prob_avg)

#test ggplot
prob_plot_theta<- ggplot(data=probs, aes(x=Theta, y=prob_correct, color=item)) +
  geom_line() +
  theme_light() +
  scale_x_continuous(name=expression(theta))+
  theme(axis.title.y = element_blank()) +
  ggtitle(expression(paste("Probability of Correct Response by ",theta," and Fraction Correct")))

prob_plot_num_correct<- ggplot(data=probs, aes(x=num_correct, y=prob_correct, color=item)) +
  geom_smooth() +
  theme_light() +
  scale_x_continuous(name="Number Correct", breaks=c(1,3,5,7,9,11,13,15))+
  theme(axis.title.y = element_blank()) +
  ggtitle(str_wrap("Probability of Correct Response on Six 4th Grade Level Items by Fraction Correct on All Math Items", 60))

# prob_plot_theta
prob_plot_num_correct
# ggarrange(prob_plot_theta, prob_plot_num_correct,
#           nrow=2)



```



```{r math_cutscore_sumstats, echo=FALSE}

math_cutscores <- data.frame(math, num_correct, school_ipw)

#set math cutscore to 9, which is around where the students get average 4th grade level item at 50% rate
math_cutscores <- math_cutscores %>%
  mutate(cut_score_14=as.numeric(num_correct>=14))

skim(math_cutscores) %>%
    dplyr::select(-level, -type, -value) %>%
     spread(stat, formatted) %>%
     dplyr::select(variable, mean, sd, p0, p25, p50, p75, p100, complete, missing, hist) %>%
  kable() %>%
  kable_styling()

```




```{r tif, eval=FALSE, echo=FALSE, warning=FALSE}
#########
#Language
########
#use the  plotting tools of mirt, but make them look nicer in ggplot
plt<-plot(irt_lang_2PL, type='rxx', theta_lim=c(-3,3), main="Test Reliability Language", par.settings=simpleTheme(lty=1:23, lwd=2), auto.key=list(points=FALSE, lines=TRUE, columns=23))

plt_test_info<-plot(irt_lang_2PL, type='info', theta_lim=c(-3,3), main="Test Information Function Language", par.settings=simpleTheme(lty=1:23, lwd=2), auto.key=list(points=FALSE, lines=TRUE, columns=23))


#str(plt) #find the data
#plt$panel.args
pltdata_lang <- data.frame(lapply(plt$panel.args, function(x) do.call(cbind, x))[[1]]) %>%
  mutate(test="Language")

pltdata_test_info_lang <- data.frame(lapply(plt_test_info$panel.args, function(x) do.call(cbind, x))[[1]]) %>%
  mutate(test="Language")


#########
#Math
########
#use the  plotting tools of mirt, but make them look nicer in ggplot
plt_math<-plot(irt_math_2PL, type='rxx', theta_lim=c(-3,3), main="Test Reliability ", par.settings=simpleTheme(lty=1:23, lwd=2), auto.key=list(points=FALSE, lines=TRUE, columns=23))

plt_test_info_math<-plot(irt_math_2PL, type='info', theta_lim=c(-3,3), main="Test Information Function ", par.settings=simpleTheme(lty=1:23, lwd=2), auto.key=list(points=FALSE, lines=TRUE, columns=23))


#str(plt) #find the data
#plt$panel.args
pltdata_math <- data.frame(lapply(plt_math$panel.args, function(x) do.call(cbind, x))[[1]]) %>%
  mutate(test="Math")

pltdata_test_info_math <- data.frame(lapply(plt_test_info_math$panel.args, function(x) do.call(cbind, x))[[1]]) %>%
  mutate(test="Math")

#combine math and language data
pltdata <- pltdata_lang %>%
  bind_rows(pltdata_math)

pltdata_test_info <- pltdata_test_info_lang %>%
  bind_rows(pltdata_test_info_math)

#create graph labels
test_rel<-fig_num(name='test_rel_math', caption = "Test Reliability Function - Math & Language")

test_info<-fig_num(name='test_info_math', caption = "Test Information Function - Math & Language")

#plot the test information function & test reliability
plt_r_math<-ggplot(pltdata, aes(x, y, colour=test)) + 
  geom_line(size=0.75) + 
  ggtitle(test_rel) +
  xlab('Teacher Ability') + 
  ylab('Test Information') + 
  theme(legend.text=element_text(size=12)) + 
  expand_limits( y = c(0,1))

ggplotly(plt_r_math)

plt_i_math<-ggplot(pltdata_test_info, aes(x, y, colour=test)) + 
  geom_line(size=0.75) + 
  ggtitle(test_info) +
  xlab('Teacher Ability') + 
  ylab('Test Reliability') + 
  theme(legend.text=element_text(size=12)) +
  expand_limits( y = 0)

ggplotly(plt_i_math)


```




```{r, eval=FALSE, echo=FALSE, warning=FALSE, message=FALSE}


#===============
# Plot Item Curves 
#===============

#generate item information data


#use the  plotting tools of mirt, but make them look nicer in ggplot
#Language
item_plt_lang<-plot(irt_lang_2PL, type='infotrace', facet_items=FALSE, theta_lim=c(-3,3))


item_plt_lang_dta <- data.frame(lapply(item_plt_lang$panel.args, function(x) do.call(cbind, x))[[1]]) %>%
  mutate(test="Language")

item_plt_lang_dta$name <- rep(colnames(language), each = 200)


#Math
item_plt_math<-plot(irt_math_2PL, type='infotrace', facet_items=FALSE, theta_lim=c(-3,3))


item_plt_math_dta <- data.frame(lapply(item_plt_math$panel.args, function(x) do.call(cbind, x))[[1]]) %>%
  mutate(test="Math")

item_plt_math_dta$name <- rep(colnames(math), each = 200)

#Append math and language databases
item_plt_dta <- item_plt_math_dta %>%
  bind_rows(item_plt_lang_dta)

#merge on item labels
item_plt_dta <- item_plt_dta %>%
  left_join(teacher_metadata)

#set figure name
icc_fig <- fig_num(name='icc_fig', caption = "Item Characteristic Plots")


linked_df<-SharedData$new(item_plt_dta)

# get list of colors
qual_col_pals = brewer.pal.info[brewer.pal.info$category == 'qual',]
col_vector = unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals)))

lngth<-length(colnames(teacher_assessment_language)) + length(colnames(teacher_assessment_math))
pal <- sample(col_vector, lngth)

bscols(widths=c(3,NA),
  list(
      filter_select("subject", "Subject", linked_df, ~test),
      filter_select("item", "Item", linked_df, ~name)
  ),
  plot_ly(linked_df, x=~x, y=~y, color=~name, colors = ~pal, type='scatter', mode='lines',
               width = 800, height = 800,
          text=~paste("Item:",name, "<br> Label:", varlabel,
                     "<br> ICC:", y, "<br> Teacher Ability", x)) %>%
    layout(title=icc_fig,
           xaxis=list(title="Teacher Ability"),
           yaxis=list(title="Item Characteristic Curve Value"))

)




```




