---
title: "Pakistan (Punjab) Sampling"
author: "Brian Stacy"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)
library(tidyverse)
library(here)
library(readxl)
library(haven)
library(flextable) 
library(srvyr)

#Country name
country <-'PAK'
country_name <- "Pakistan"
year <- '2022'
province <- "Punjab"
#specify name of sampling frame file.  This needs to be a csv file
#ublic_file_frame<-"List of standalone primary schools with enrollment & teachers - as per Census 2022-23.xlsx"
public_file_frame<-"Copy of List of primary portion schools - as per census 2022-23.xlsx"
saber_frame <- 'Panel_Sample_2021.xls'

set.seed(8473227)

#########################
# File paths #
#########################
#The download_folder will be the location of where raw data is downloaded from the API
#The save_folder will be the location of where cleaned data is stored



if (str_to_lower(Sys.getenv("USERNAME")) == "wb469649" ){
  #project_folder  <- "//wbgfscifs01/GEDEDU/datalib-edu/projects/gepd"
  project_folder  <- paste0("C:/Users/",str_to_lower(Sys.getenv("USERNAME")),"/WBG/HEDGE Files - HEDGE Documents/GEPD/CNT/")
  sampling_folder <-file.path(paste(project_folder,country,paste(country,year,"GEPD", sep="_"),paste(country,year,"GEPD_v01_M", sep="_"),"Data",province,"/Sampling", sep="/"))
  
} else if (str_to_lower(Sys.getenv("USERNAME")) == "wb577189" ){

  project_folder  <- paste0("C:/Users/",str_to_lower(Sys.getenv("USERNAME")),"/OneDrive - WBG/GEPD/CNT/")
  sampling_folder <-file.path(paste(project_folder,country,paste(country,year,"GEPD", sep="_"),paste(country,year,"GEPD_v01_M", sep="_"),"Data",province,"/Sampling", sep="/"))
  
} else {
  download_folder <- choose.dir(default = "", caption = "Select folder to open data downloaded from API")
  save_folder <- choose.dir(default = "", caption = "Select folder to save final data")

}

```

## Introduction

This file outlines the sampling strategy for Pakistan (Punjab).

## General Notes on Sampling
The aim of the Global Education Policy Dashboard school survey is to produce nationally representative estimates, which will be able to detect changes in the indicators over time at a minimum power of 80% and with a 0.05 significance level.  We also wish to detect differences by urban/rural location. 

For our school survey, we will employ a two-stage random sample design, where in the first stage a sample of around 200 schools, based on local conditions, is drawn, chosen in advance by the Bank staff.  In the second stage, a sample of teachers and students will be drawn to answer questions from our survey modules, chosen in the field.  A total of 10 teachers will be sampled for absenteeism.  Five teachers will be interviewed and given a content knowledge exam.  Three 1st grade students will be assessed at random, and a classroom of 4th grade students will be assessed at random.  Stratification will be based on the school’s urban/rural classification and based on region. When stratifying by region, we will work with our partners within the country to make sure we include all relevant geographical divisions. 



 

Sampling Approach for Global Education Policy Dashboard

This document will provide an overview of the sampling strategy used in the Global Education Policy Dashboard (GEPD) surveys, as well as remaining questions.  New data for the dashboard will be collected using three main instruments: a School Survey, an Expert Survey, and a Survey of Public Officials. More information pertaining to each can be found below.  The goal of the Global Education Policy Dashboard is to provide summary information at the national level on a set of 35 indicators and to allow countries to track progress on those indicators over a short time frame (every 2 years).  Specifically, we aim to produce nationally representative estimates, which will be able to detect changes in the indicators over time at a minimum power of 80% and with a 0.05 significance level.  We also wish to disaggregate by urban/rural.

School Survey: The School Survey will collect data primarily on Practices (the quality of service delivery in schools), but also on some de facto Policy and school-level Politics indicators.  It will consist of streamlined versions of existing instruments—including SDI and SABER SD on teachers, 4th grade students, and inputs/infrastructure, TEACH on pedagogical practice, GECDD on school readiness of young children, and DWMS on management quality—together with new questions to fill gaps in those instruments.  Though the number of modules is similar to the full version of SDI, the number of items within each module is significantly lower. In each country, this survey will be administered in a nationally representative sample of 250 schools, selected through stratified  random sampling. As currently envisioned, the School Survey will include 8 short modules.
Expert Survey: The Expert Survey will collect information to feed into the policy indicators.  This survey will be filled out by key informants in each country, drawing on their knowledge to identify key elements of the policy framework (as in the SABER approach to policy-data collection that the Bank has used over the past 7 years).  The survey will have 4 modules with each including approximately ten questions.

Survey of Public Officials: The Survey of Public Officials will collect information about the capacity and orientation of the bureaucracy, as well as political factors affecting education outcomes. This survey will be a streamlined and education-focused version of the civil-servant surveys that the Bank’s Bureaucracy Lab has implemented recently in several countries, and the dashboard team is collaborating closely with DEC and Governance GP staff to develop this instrument.  As currently envisioned, the survey will be administered to a random sample of about 200 staff serving in the central education ministry and district education offices.  It will include questions about technical and leadership skills, work environment, stakeholder engagement, clientelism, and attitudes and behaviors.


## Punjab Sampling

200 schools will be drawn.  The strata



```{r}




#read sample frame
public_df=read_excel(paste(sampling_folder, public_file_frame, sep="/")) 

df_raw<-public_df %>%
    mutate(
            total_enrollment=total_t,
            total_katchi_enrollment=k_t,
            total_katchi_enrollment_boys=k_b,
            total_katchi_enrollment_girls=k_g,
            total_ece_enrollment=ece_t,
            total_ece_enrollment_boys=ece_b,
            total_ece_enrollment_gils=ece_g,
            total_1st_enrollment=cls1_t,
            total_1st_enrollment_boys=cls1_b,
            total_1st_enrollment_girls=cls1_g,       
            total_4th_enrollment_boys=cls4_b, 
            total_4th_enrollment_girls=cls4_g,      
            total_4th_enrollment=cls4_t,
            total_5th_enrollment_boys=cls5_b, 
            total_5th_enrollment_girls=cls5_g,      
            total_5th_enrollment=cls5_t,      
            rural=if_else(csl_area=="Rural", 1,0))

# read in SABER/SDI sample
saber_sample_df <- read_excel(paste(sampling_folder, saber_frame, sep="/"))

#join the frames
df_frame_joined_df <- df_raw %>%
  left_join(saber_sample_df %>% mutate(saber_sampled="SABER school"), by=c('csl_emis_code'='EmisCode'))

districts <- df_frame_joined_df %>% group_by(saber_sampled, csl_district, csl_area) %>% summarise(n=n())
```





```{r}

df_updated_gepd <- df_frame_joined_df %>%
  filter(total_1st_enrollment>=3,
         total_4th_enrollment>=3) 

df_updated <- df_frame_joined_df %>%
  filter(total_ece_enrollment+total_katchi_enrollment>=3,
         total_1st_enrollment>=3,
         total_4th_enrollment>=3,
         total_5th_enrollment>=3)
```

Typically for the GEPD only schools with at least 3 1st grade and 3 4th grade students will be selected.  Applying these restrictions results in `r nrow(df_updated_gepd)` schools eligible.

However, there is interest in interviewing pre-primary students and students in 5th grade for the AIM-ECD assessment and the AMPL-b assessment.  As a result, additionaly schools are excluded that do not have at least 3 kachi and 3 5th grade students.  This results in `r nrow(df_updated)` being eligible.  There were `r nrow(df_updated_gepd %>% filter(total_ece_enrollment+total_katchi_enrollment<3))` schools that were eliminated because of the preprimary restriction and `r nrow(df_updated_gepd %>% filter(total_5th_enrollment<3))` because of the grade 5 restriction.



Basic summary stats of overall frame

```{r}
#level
df_updated %>% 
  group_by(csl_level) %>% 
  summarise(n=n(),Students=sum(total_enrollment, na.rm = TRUE)) %>% 
  flextable() %>% 
  add_header_lines('Number of Schools by Level') %>% 
  autofit()

#Tehsil
df_updated %>% 
  group_by(csl_district) %>% 
  summarise(Schools=n(),Students=sum(total_enrollment, na.rm = TRUE)) %>% 
  flextable() %>% 
  add_header_lines('Number of Schools by District') %>% 
  autofit()

#Gender
df_updated %>% 
  group_by(csl_official_school_type) %>% 
  summarise(Schools=n(),Students=sum(total_enrollment, na.rm = TRUE)) %>% 
  flextable() %>% 
  add_header_lines('Number of Schools by Gender') %>% 
  autofit()

#Urban/rural
df_updated %>% 
  group_by(csl_area) %>% 
  summarise(Schools=n(),Students=sum(total_enrollment, na.rm = TRUE)) %>% 
  flextable() %>% 
  add_header_lines('Number of Schools by Urban/Rural') %>% 
  autofit()




```

# Sampling

```{r eval=FALSE, include=FALSE}
#set baseline for sampling frame.  Manual editing done in excel
strata_df_200 <- df_updated %>%
  filter(!is.na(total_enrollment)) %>%
   group_by(csl_district,csl_area ) %>%
   summarise(nstudents_district=sum(total_enrollment),
                      total_district=n()
 ) %>%
   ungroup() %>%
   mutate(sample_size=200*round(nstudents_district/sum(nstudents_district),2))

write_excel_csv(strata_df_200, file=paste0(sampling_folder, "/GEPD_Punjab_strata_200_",Sys.Date(),".csv"))
```


```{r large, echo=TRUE}


# set the numbers of schools selected by strata (grade)
strata_df_200 <- read_csv(paste0(sampling_folder, "/GEPD_Punjab_final_strata_200_2023-10-02.csv"))


sample_df_200 <- df_updated %>%
  mutate(saber_sampled=if_else(is.na(saber_sampled),"Not SABER",saber_sampled)) %>%
  left_join(strata_df_200) %>%
  mutate(sample_size=if_else(is.na(sample_size),0,sample_size)) %>%
  ungroup() %>%
  mutate(
    totalstudents=sum(total_4th_enrollment),
  ) %>%
  group_by(csl_district,csl_area, saber_sampled) %>%
  mutate(strata_count=n(),
         strata_size=sum(total_4th_enrollment),
         strata_school_prob=strata_size/totalstudents) %>%
  sample_n(size = min(sample_size), weight= total_4th_enrollment) %>%
  ungroup() %>%
  mutate(strata_prob=(sample_size)*(total_4th_enrollment/strata_size),
         ipw=strata_school_prob*(1/strata_prob),
         strata=paste(csl_district,csl_area, saber_sampled, sep=" - "))



write_excel_csv(sample_df_200, file=paste0(sampling_folder, "/GEPD_Punjab_sample_200_",Sys.Date(),".csv"))

weights_df_200 <- df_updated %>%
  mutate(saber_sampled=if_else(is.na(saber_sampled),"Not SABER",saber_sampled)) %>%
  left_join(strata_df_200) %>%
  mutate(sample_size=if_else(is.na(sample_size),0,sample_size)) %>%
  ungroup() %>%
  mutate(
    totalstudents=sum(total_4th_enrollment),
  ) %>%
  group_by(csl_district,csl_area, saber_sampled) %>%
  mutate(strata_count=n(),
         strata_size=sum(total_4th_enrollment),
         strata_school_prob=strata_size/totalstudents) %>%

  mutate(strata_prob=(sample_size)*(total_4th_enrollment/strata_size),
         ipw=strata_school_prob*(1/strata_prob),
         strata=paste(csl_district,csl_area, saber_sampled, sep=" - "))


write_excel_csv(weights_df_200, file=paste0(sampling_folder, "/GEPD_Punjab_weights_200_",Sys.Date(),".csv"))

```


# Replacement Schools

Below is a list of replacement schools for each sampled school. Replacement schools were randomly selected among the set of schools in the district, not including the orginally sampled schools. Each row contains the school name, location, and other information for each replacement school.  In the final 5 columns of the database is the school code, school name, region, and district of the originally sampled school for which this school serves as a replacement. 



```{r}
#| label: tbl-update_dataset_public
#| tbl-cap: Sanity Checks


#define sampled schools in sample dataset
sample_chosen <- read_csv(paste0(sampling_folder, "/GEPD_Punjab_sample_200_","2023-10-31",".csv")) %>%
  mutate(sample="Sampled School") 

#add sample schools back to original database
data_set_updated_chosen <- df_updated_gepd %>%
  left_join(sample_chosen) 

#get list of tehsil
sampled_districts <- sample_chosen %>%
  group_by( csl_district,csl_area) %>% 
  summarise(sampled_districts=n()
            )

# select one replacement per district
sample_replace <- data_set_updated_chosen %>%
  left_join(sampled_districts) %>%
  filter(!is.na(sampled_districts)) %>%
  filter(is.na(sample)) %>%
  group_by(csl_district,csl_area) %>%
    ungroup() %>%
  mutate(
    totalstudents=sum(total_4th_enrollment),
  ) %>%
  group_by(csl_district,csl_area) %>%
  sample_n(2*mean(sampled_districts), weight=total_4th_enrollment) %>% #select two replacement schools
  mutate(sample='Replacement School') %>%
  arrange(csl_district,csl_area, csl_school_name) 

sample_replace2 <- sample_chosen %>%
    bind_rows(sample_chosen) %>% #add a duplicate observation for matching to two replacement schools
    arrange(csl_district,csl_area, csl_school_name)  


#add in school info for school that will be replaced
sample_replace$replaced_School_Name=sample_replace2$csl_school_name
sample_replace$replaced_EmisCode=sample_replace2$csl_emis_code
sample_replace$replaced_District=sample_replace2$csl_district



sample_replace %>%
  select(csl_school_name, csl_emis_code, csl_district, replaced_School_Name, replaced_EmisCode, replaced_District) %>%
  DT::datatable( caption = 'List of Replacement Schools Chosen for Public School Sample') 

sample_replace <- sample_replace %>%
  select(csl_school_name, csl_emis_code, csl_district, replaced_School_Name, replaced_EmisCode, replaced_District, everything())
  
write_excel_csv(sample_replace, paste(sampling_folder, '/GEPD_Punjab_replacement_schools_', Sys.Date(),  '.csv', sep=""))


```


## Evaluation of Sample Size

Compare statistics when taking varying subsamples of the main sample of schools.

```{r eval=FALSE, include=FALSE}
student_data <- read_dta(paste(sampling_folder, '1.StudentData_BLvEL.dta', sep="/"))

#get unique school ids
school_ids <- unique(student_data$scode_original)
sizes <- seq( 50,250, by = 10)
# create a new vector containing sizes but repeated 100 times
sizes <- rep(sizes, each = 100)

# Create an empty data frame to store the results
results_df <- data.frame(Size = numeric(0), Avg_Test_Score = numeric(0), Avg_Test_Score_se = numeric(0))

#write a function to calculate the mean
svy_size_experiment <- function(size) {
  
  #randomly sample from list of schools
    school_id_sample <- sample(school_ids, size)
    
    srvy_df <- student_data %>%
      filter(!is.na(BL_Weight)) %>%
      filter(!is.na(m5_el_AllTest_TestScore)) %>%
      filter(scode_original %in% school_id_sample) %>%
      group_by(scode_original) %>%
      summarise(m5_el_AllTest_TestScore=mean(m5_el_AllTest_TestScore),
                BL_Weight=mean(BL_Weight)) %>%
      ungroup() %>%
      as_survey_design(
                       weight=BL_Weight)
  
  results <- srvy_df %>% 
    summarise(avg_test_score=survey_mean(`m5_el_AllTest_TestScore`))
  
   
}

## Loop through the sizes and apply the svy_size_experiment function
for (size in sizes) {
  result <- svy_size_experiment(size)
  results_df <- rbind(results_df, data.frame(Size = size, Avg_Test_Score = result$avg_test_score,
                      Avg_Test_Score_se=result$avg_test_score_se))
}

results_collapsed_df <- results_df %>%
  group_by(Size) %>%
  summarise(Avg_Test_Score=mean(Avg_Test_Score),
            Avg_Test_Score_se=mean(Avg_Test_Score_se))

ggplot(results_collapsed_df, aes(x=Size, y=Avg_Test_Score)) +
  geom_point() +
  geom_errorbar(aes(ymin=Avg_Test_Score-1.96*Avg_Test_Score_se,ymax=Avg_Test_Score+1.96*Avg_Test_Score_se)) +
  theme_bw() +
  expand_limits(y=c(0,1)) +
  labs(
    title=str_wrap('Mean Student Test Score Point Estimates and Std Errors from Punjab SABER under Different Sampling #s',50)
  )



```

```{r eval=FALSE, fig.height=6, fig.width=12, include=FALSE}
ggplot(results_collapsed_df, aes(x=Size, y=Avg_Test_Score_se)) +
         geom_col(fill='darkred') +
         geom_text(aes(label=paste0("Sample Size: ",round(Size,0), ", Std Error: ", round(Avg_Test_Score_se,3))), hjust=-0.5) +
         coord_flip() +
         theme_bw() +
  labs(
    title=str_wrap('Mean Student Test Score Std Errors from Punjab SABER under Different Sampling #s',150)
  )
```
Do same for clean toilets

```{r eval=FALSE, include=FALSE}
principal_data <- read_dta(paste(sampling_folder, 'PrincipalData_BL_Anonymized.dta', sep="/"))

#get unique school ids
school_ids <- unique(principal_data$scode)
sizes <- seq( 50,250, by = 10)
# create a new vector containing sizes but repeated 100 times
sizes <- rep(sizes, each = 100)

# Create an empty data frame to store the results
results_df <- data.frame(Size = numeric(0), toilet_clean = numeric(0), toilet_clean_se = numeric(0))

#write a function to calculate the mean
svy_size_experiment <- function(size) {
  
  #randomly sample from list of schools
    school_id_sample <- sample(school_ids, size)
    
    srvy_df <- principal_data %>%
      filter(!is.na(weight)) %>%
      filter(!is.na(m2_b5)) %>%
      filter(scode %in% school_id_sample) %>%
      ungroup() %>%
      as_survey_design(
                       weight=weight)
  
  results <- srvy_df %>% 
    summarise(toilet_clean=survey_mean(`m2_b5`))
  
   
}

## Loop through the sizes and apply the svy_size_experiment function
for (size in sizes) {
  result <- svy_size_experiment(size)
  results_df <- rbind(results_df, data.frame(Size = size, toilet_clean = result$toilet_clean,
                      toilet_clean_se=result$toilet_clean_se))
}

results_collapsed_df <- results_df %>%
  group_by(Size) %>%
  summarise(toilet_clean=mean(toilet_clean),
            toilet_clean_se=mean(toilet_clean_se))

ggplot(results_collapsed_df, aes(x=Size, y=toilet_clean)) +
  geom_point() +
  geom_errorbar(aes(ymin=toilet_clean-1.96*toilet_clean_se,ymax=toilet_clean+1.96*toilet_clean_se)) +
  theme_bw() +
  expand_limits(y=c(0,1)) +
  labs(
    title=str_wrap('Mean Clean Toilet Point Estimates and Std Errors from Punjab SABER under Different Sampling #s',50)
  )



```

```{r eval=FALSE, fig.height=6, fig.width=12, include=FALSE}
ggplot(results_collapsed_df, aes(x=Size, y=toilet_clean_se)) +
         geom_col(fill='darkred') +
         geom_text(aes(label=paste0("Sample Size: ",round(Size,0), ", Std Error: ", round(toilet_clean_se,3))), hjust=-0.5) +
         coord_flip() +
         theme_bw() +
  labs(
    title=str_wrap('Mean Clean Toilet Std Errors from Punjab SABER under Different Sampling #s',150)
  )

```

# Sanity Checks

Below I will use the survey weights to estimate aspects of the school that are available in the sampling frame.  The population mean from the full sampling frame is compared to the estimated mean from the school sample using the sampling weights. Estimated means very far from the population mean can indicate there is something wrong with the weights or that the school sample is biased.

The estimates based on the school weights are similar and within the confidence interval of those produced using the sampling frame.

```{r}
library(srvyr)
#sanity check of the sampling weights and results
# use weights to estimate population average of internet prevalence

df_raw %>%
  ungroup() %>%
  summarise(total_b=mean(total_b, na.rm = TRUE),
            cls3_t=mean(cls3_t, na.rm = TRUE),
            cls3_g=mean(cls3_g, na.rm = TRUE),
            cls3_b=mean(cls3_b, na.rm = TRUE)) %>%
  flextable() %>%
  add_header_lines("Raw Sampling Frame Population estimate")

df_updated_gepd %>%
  ungroup() %>%
  summarise(total_b=mean(total_b, na.rm = TRUE),
            cls3_t=mean(cls3_t, na.rm = TRUE),
            cls3_g=mean(cls3_g, na.rm = TRUE),
            cls3_b=mean(cls3_b, na.rm = TRUE)) %>%
  flextable() %>%
  add_header_lines("Population estimate")




sample_df_200 %>%
  left_join(weights_df_200) %>%
  ungroup() %>%
  as_survey_design(strata=c('csl_district','csl_area', 'saber_sampled'),
                   weight=ipw) %>%
    summarise(total_b=survey_mean(total_b, na.rm = TRUE),
            cls3_t=survey_mean(cls3_t, na.rm = TRUE),
            cls3_g=survey_mean(cls3_g, na.rm = TRUE),
            cls3_b=survey_mean(cls3_b, na.rm = TRUE)
              ) %>%
  flextable() %>%
  add_header_lines("Estimate based on Schools Visited and Sampling Weights")
```

