---
title: "GEPD Technical Note"
author: "Global Education Policy Dashboard Team"
date: "1/27/2020"
output:
  html_document:
    df_print: paged
    toc: yes
  word_document:
    toc: yes
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(knitr)
library(captioner)
library(srvyr)
#produce caption for tables/figures
  tab_num<-captioner(prefix="Table")
  fig_num<-captioner(prefix="Figure")
  

code_inclusion=TRUE  
  
```


# Introduction

Many countries, despite having significantly increased access to education for their children and youth, now realize that they are facing a learning crisis (World Development Report 2018). In low- and middle-income countries, where enrollment in primary school is nearly universal, 53% of children cannot read and understand a simple story by the end of primary. That is children cannot read a short age-appropriate story and successfully answer a series of questions on the content of that story by the end of primary school. This reality underlines that schooling is not the same as learning—even though education policy often assumes that it is. \
The World Development Report 2018 argued that the learning crisis has multiple causes: poor service delivery in schools and communities, unhealthy politics and low bureaucratic capacity, and policies that are not aligned toward learning for all. To tackle the crisis and improve student learning for all, countries need to know where they stand on these three key dimensions—practices (or service delivery), policies, and politics. But providing such a systemwide overview requires better measurement. Many of these drivers of learning are not captured by existing administrative systems. And although new measurement tools capture some of those aspects well, no single instrument pulls together data on all these areas. This gap leaves policymakers in the dark about what is working and what isn’t.

To fill this gap, the World Bank, with support from the Bill and Melinda Gates Foundation, the UK’s Department for International Development, and the Government of Japan, has launched a Global Education Policy Dashboard, which measures the drivers of learning outcomes in basic education around the world. In doing so, it highlights gaps between current practice and what the evidence suggests would be most effective in promoting learning, and it gives governments a way to set priorities and track progress as they work to close those gaps.

This technical note outlines some of the technical aspects of the overall project as well as its field work, instruments, indicators, and scores. The purpose is to be transparent about the technical decisions that have been made along the way as well as to provide evidence that speaks to the soundness of the measures offered by the Global Education Policy Dashboard. The note is divided into 3 sections that cover the 1) development of the instruments, 2) the field work, and 3) the constructing of the indicators. These three sections are followed by a set of annexes that provide additional relevant information.

# Section 1 – Development of the GEPD Instruments
The dashboard project collects new data in each country using three new instruments: A School Survey, a Policy Survey, and a Survey of Public Officials. Data collection involves school visits, classroom observations, legislative reviews, teacher and student assessments, and interviews with teachers, principals, and public officials. In addition, the project draws on some existing data sources to complement the new data it collects. A major objective of the GEPD project was to develop focused, cost-effective instruments and data-collection procedures, so that the dashboard can be inexpensive enough to be applied (and re-applied) in many countries. The team achieved this by streamlining and simplifying existing instruments, and thereby reducing the time required for data collection and training of enumerators.

More information pertaining to each of the three instruments can be found below:

* School Survey: The School Survey collects data primarily on Practices (the quality of service delivery in schools), but also on some de facto Policy and school-level Politics indicators.  It consists of streamlined versions of existing instruments—including Service Delivery Surveys on teachers and inputs/infrastructure, TEACH on pedagogical practice, Global Early Child Development Database (GECDD) on school readiness of young children, and the Development World Management Survey (DWMS) on management quality—together with new questions to fill gaps in those instruments.  Though the number of modules is similar to the full version of the Service Delivery Indicators (SDI) Survey, the number of items and the complexity of the questions within each module is significantly lower. The School Survey includes 8 short modules: School Information, Teacher Presence, Teacher Survey, Classroom Observation, Teacher Assessment, Early Learner Direct Assessment, School Management Survey, and 4th-grade Student Assessment.    
* Policy Survey: The Policy Survey collects information to feed into the Policy de jure indicators. This survey is filled out by key informants in each country, drawing on their knowledge to identify key elements of the policy framework (as in the SABER approach to policy-data collection that the Bank has used over the past 7 years).  The survey includes questions on policies related to teachers, school management, inputs and infrastructure, and learners.    
* Survey of Public Officials: The Survey of Public Officials collects information about the capacity and orientation of the bureaucracy, as well as political factors affecting education outcomes. This survey is a streamlined and education-focused version of the civil-servant surveys that the Bureaucracy Lab (a joint initiative of the Governance Global Practice and the Development Impact Evaluation unit of the World Bank) has implemented recently in several countries. The survey includes questions about technical and leadership skills, work environment, stakeholder engagement, impartial decision-making, and attitudes and behaviors.    
A crucial part of the streamlining process and the development of the three instruments involved a rigorous qualitative research process to identify the most relevant questions to comprise the indicators. Throughout this process, numerous experts within and outside the World Bank were consulted to identify such concepts and questions. This process alone resulted in a significant reduction in terms of the length of the surveys as well as their complexity. Additionally, for some of the modules of the School Survey, extensive psychometric analyses were conducted to inform the streamlining process. These modules were primarily those involving assessments – Teacher Assessment, 4th Grade Assessment, and Early Grade Assessment. 
      
      
More information pertaining to each of the three instruments can be found in the Global Education POlicy Dashboard Booklet.

# Proficiency Cutoffs

For our learning indicators and our indicator of teaching proficiency, we had to set thresholds for minimal proficiency. Below we will discuss how these proficiency cutoffs were determined.

### Student Learning Assessment

The SDI student test was designed as a one-on-one evaluation with enumerators reading out instructions to students in their mother tongue. This was done so as to build up a differentiated picture of students’ cognitive skills; i.e. oral one-to-one testing which allows testing whether a child can solve a mathematics problem even when his/her reading ability is so low that he/she would not be able to attempt the problem independently. The language test (implemented in the language of instruction: English, French, Swahili, or Portuguese) ranged from simple tasks testing letter and word recognition to a more challenging reading comprehension test.  The mathematics test ranged from recognizing and ordering numbers, to addition of one- to three-digit numbers, to one- and two-digit subtraction, to single digit multiplication and division.

The sub-domains for the literacy section are:

* Letter Identification
*	Word Recognition
*	Reading Comprehension Story I  
* Reading Comprehension Story II 

The Reading Comprehension Story II set of items were added to the standard SDI assessment by our team, and came from a publicly released items from the PIRLS assessment.

The sub-domains for the math section are:

*	Number Sense
*	Arithmetic
*	Word Problem
*	Sequences


In order to determine whether or not a child was proficient based on our assessment, out team consulted with a set of experts to complete a standard setting exercise where each expert was asked to rate whether a minimally proficient student in the subject should be able to answer the item correctly using the global proficiency framework being designed by UIS.  The result of that exercise was that we would expect a minimally proficient child to answer 20/24 questions correctly on our literacy section and 14/17 points on our mathematics assessment.  Students scoring at least this many points on our assessment are rated as proficient and otherwise rated not proficient.

INCLUDE LIST OF EXPERTS WE CONSULTED TO THANK THEM HERE

### Teacher Content Knowledge Assessment

The objective of the teacher test is three-fold. The first objective is to examine whether teachers have the mastery of the subjects they are teaching. This is interpreted as the minimum knowledge required for the teacher to be effective. In addition, the test also examines the extent to which teachers demonstrate mastery of subject content skills that are above the level they are teaching at and finally, mastery of pedagogic skills.

To simplify the administration of the test it was designed as a marking exercise, in which teachers are asked to mark and correct a hypothetical student's exam. The Language test was administered to teachers teaching language, or language and other subjects, and the mathematics test was administered to teacher teaching mathematics, or mathematics and other subjects. The test was validated against 13 Sub-Saharan primary curricula.^[The countries included for the review were: Botswana, Ethiopia, Gambia, Kenya, Magadascar, Mauritius, Namibia, Nigeria, Rwanda, Seychelles, South Africa, Tanzania and Uganda. See David Johnson, Andrew Cunningham and Rachel Dowling (2012) "Teaching Standards and Curriculum Review", prepared as background document for the SDI Survey.] ^[While some SDI countries were not part of the review, before doing the SDI survey the SDI team verified that the school curriculum was compatible with the SDI teacher and student test. For more information see SDI Technical report for each specific country.]

The language test consisted of two sections. The first section asked teachers to assess pupil language literacy by correcting a primary school pupil language test. The teachers have to correct whether the "student answer" is correct, and in case it is incorrect, has to write the correct answer. The second section asks teachers to correct a letter written by a child in 4th grade. The teachers have to correct the letter for grammar, punctuation (between sentences and within sentences), spelling, syntax, and salutation by circling the mistakes and writing the correction on the line.
The mathematics test asks teachers to assess pupil numeracy literacy by correcting a primary school pupil mathematic test. The teachers have to correct whether the "student answer" is correct, and in case it is incorrect it has to write the correct answer.

The pedagogy test consists of three sections designed to capture all the skills teachers would routinely be asked to apply when teaching. The first section asks teachers to prepare a lesson plan about road accidents based on a simple information given a text they had read. The second task asks teachers to assess children's writing on the basis of two sample letters (written by grade 4 children). Teachers have to point out the strengths and weaknesses on the student's letters, by evaluating  pupil's ability to write simple letters, use sentence structures correctly including past and present tenses, use a range of vocabulary, and use both within and between sentence punctuation.  The final task asks teachers to inspect test scores of 10 children, aggregate them and make some statements about learning patterns.

We set a threshold of 80% on the math and language assessment for a teacher being minimally proficient.  This standard was used in the Service Delivery Indicators initiative, and we are using it as a benchmark as well.

### 1st Grade Assessment

Our first grade assessment tool was derived mostly from the MELQO assessment developed as an open source tool to measure early childhood development in the domains of numeracy, literacy, socio-emotional skills and numeracy.  For more details on the development of this initiative see:

https://unesdoc.unesco.org/ark:/48223/pf0000248053

The MELQO instrument was designed to measure development of children around the age of six years old.  Our target group, 1st graders, is slightly older and we did some adaptation in which we removed some items and added items on simple sentence reading to better match what is expected of older children.


The sub-domains for the literacy section are:

*	Expressive Vocabulary
* Letter Identification
*	Word Recognition
*	Sentence Reading
*	Listening Comprehension Story 
*	Name Writing
*	Print Awareness


The sub-domains for the math section are:

*	Verbal Counting
*	Producing a Set
*	Number Identification
*	Number Comparison
*	Simple Addition


The sub-domains for the socio-emotional section are:

*	Perspective Taking/Empathy
*	Conflict Resolution

The sub-domains for the executive functioning section are:

*	Working Memory/Backward Digit Spans
*	Follow Instructions/Head, Toes, Knees, Shoulders Task

Our threshold for proficiency on our 1st grade assessment is to score at least 80% of the items correctly. We validated this approach by calculating the percent correct in the top 25% highest scoring schools in Peru on our 4th grade dashboard assessment and found that students in these schools answered around this percentage of items correct.

# Stop Light Scoring System

We use the following system for categorizing our main indicators into three levels: On Target, Caution, and Needs Improvement.

For our indicators ranging from 0-100, we use the following system:

1. On Target - Values at least 90%  
2. Caution - Values between 70-90  
3. Needs improvement - Values under 70%  

For our indicators ranging 1-5, we use the following system:

1. On Target - Values at least 4  
2. Caution - Values between 2 and 4  
3. Needs improvement - Values 2 and under  

# Sampling

## General Notes on Sampling
The aim of the Global Education Policy Dashboard school survey is to produce nationally representative estimates, which will be able to detect changes in the indicators over time at a minimum power of 80% and with a 0.05 significance level.  We also wish to detect differences by urban/rural location. 

For our school survey, we will employ a two-stage random sample design, where in the first stage a sample of typically around 200 schools, based on local conditions, is drawn, chosen in advance by the Bank staff.  In the second stage, a sample of teachers and students will be drawn to answer questions from our survey modules, chosen in the field.  A total of 10 teachers will be sampled for absenteeism.  Five teachers will be interviewed and given a content knowledge exam.  Three 1st grade students will be assessed at random, and a classroom of 4th grade students will be assessed at random.  Stratification will be based on the school’s urban/rural classification and based on region. When stratifying by region, we will work with our partners within the country to make sure we include all relevant geographical divisions. 

For our Survey of Public Officials, we will sample a total of 200 public officials.  Roughly 60 officials are typically surveyed at the federal level, while 140 officials will be surveyed at the regional/district level.  For selection of officials at the regional and district level, we will employ a cluster sampling strategy, where roughly 10 regional offices (or whatever the secondary administrative unit is called) are chosen at random from among the regions in which schools were sampled.  Then among these 10 regions, we also typically select around 10 districts (tertiary administrative level units) from among the districts in which schools werer sampled.  The result of this sampling approach is that for 10 clusters we will have links from the school to the district office office to the regional office to the central office.  Within the regions/districts, five or six officials will be sampled, including the head of organization, HR director, two division directors from finance and planning, and one or two randomly selected professional employees among the finance, planning, and one other service related department chosen at random.  At the federal level, we will interview the HR director, finance director, planning director, and three randomly selected service focused departments.  In addition to the directors of each of these departments, a sample of 9 professional employees will be chosen in each department at random on the day of the interview.

## Detailed Sampling Notes

Our team consulted with several sampling experts at the World Bank to discuss strategies for sampling schools.  As mentioned, the goal of our survey is to be able to detect differences across time and by urban/rural location.  The result of our consultation with experts was to use an optimal stratification strategy based on the optimal stratified sampling technique in Barcaroli (2014) which uses the genetic algorithm to produce an optimal number of strata and an optimal number of units within strata.  Optimal stratification can lead to reduced sampling error compared to alternative approaches such as cluster sampling or simple random sampling.  

Before producing the sample using the optimal stratification approach, we would define the sampling frame.  Typically, we would take all schools with at least three 1st grade and at least three 4th grade students, according to the latest school census, for inclusion in the frame.  A minimum of three 1st grade and 4th grade students was set to ensure that a sufficient number of teachers in primary school and students would be interviewed.  In order to do this, we work with the World Bank country teams and the country government to compile an up to date and detailed database containing information on schools. Depending on the country, we may or may not include private schools in the sampling frame depending on the particular country context.  The decision to include private schools is usually determined by the share of private schools that make up the total student enrollment and the ease with which we are able to enter private schools in the country.  We work with the government and the local World Bank team in making this decision.  In Peru, we included only public schools in the sampling frame, because private schools make up only a small percentage of total student enrollment.

In our stratified sampling approach, we typically use a countries 1st or 2nd level administative division (which usually is a province or department) depending on the country and the urban/rural status of the school as stratification variables.  For example, in Peru, the Departamento and urban/rural status of the school made up the stratification variables.  In cases, where private schools are also included in the sampling frame, the public/private status of the school is also included as a stratification variable.

The optimal stratification apporach is particularly useful if previous surveys have been done in the country which collect information similar to the information collected in our Dashboard.  The optimal stratification algorith will assign extra units to a stratum that has a particularly variance in our target variables.  For instance in Peru, we used data from a previous nationally representative survey which used the MELQO instrument to test Early Childhoold skills.  We were able to calculate the mean and standard deviation of the student level test scores by departamento, and we were able to assign extra sampling units to stratum with relatively high variances in these outcomes. To the extent that regions with a high variance in the MELQO test also have a high variance in our other outcomes (such as the 4th grade test scores, teacher knowledge, principal practices), we would expect this sampling approach to improve precision in these measures as well.

A quick introduction to the technical aspects of the opimal stratification approach can be found here.

https://cran.r-project.org/web/packages/SamplingStrata/vignettes/SamplingStrata.html

In all cases, where the optimal stratification algorithm was applied, we also in paralell ran a sampling approach based on a more simple stratified sampling approach where units were broken into strata and the number of units per strata was proportionate to the stratum size.  Typically, we did not find major differences in the summary statistics of the sample (in terms of average numbers of students per school, or number of schools per region) based on the optimal stratification approach compared to a more simple stratification approach.

Barcaroli G (2014). “SamplingStrata: An R Package for the Optimization of Stratified Sampling.” Journal of Statistical Software, 61(4), 1–24. http://www.jstatsoft.org/v61/i04/.



### Peru Specific Comments

MELQO data was merged with the Peru school frame in order to optimally stratify.  We stratified on the basis of urban/rual and department.  There are 25 departments in Peru. In 2017, Peru conducted an examination of around 4,500 children between 5 and 8 years old, with a median age of 6.  The MELQO exam is quite similar to our ECD examination module.  We are able to use data from this 2017 survey to choose the number of schools in each province optimally by calculating means and standard deviations by province and feeding this information into the optimal stratification algorithm.  See https://cran.r-project.org/web/packages/SamplingStrata/vignettes/SamplingStrata.html.  Provinces with low standard deviations among students in terms of their MELQO development scores are allocated fewer schools compared to an allocation that is simply based on population, and provinces with high standard deviations are allocated more schools.  

205 schools were chosen for our survey after optimally stratifying.  

To see more detailed notes on our sampling approach in Peru, please see:
https://github.com/worldbank/GEPD/blob/develop/Data/Peru/2019/Data/sampling/Sampling_Notes_Peru.html 

and

https://github.com/worldbank/GEPD/blob/develop/Data/Peru/2019/Data/sampling/SamplingStrata_Peru_shared.R

### Jordan  Specific Comments

For our school survey, we select only schools that are supervised by the Minsitry or Education or are Private schools.  No schools supervised by the Ministry of Defense, Ministry of Endowments, Ministry of Higher Education , or Ministry of Social Development are included.  This left us with a sampling frame containing 3,330 schools, with 1297 private schools and 2003 schools managed by the Minsitry of Education. The schools must also have at least 3 grade 1 students, 3 grade 4 students, and 3 teachers.

We oversampled Southern schools to reach a total of 50 Southern schools for regional comparisons.  Additionally, we oversampled Evening schools, for a total of 40 evening schools.

To see more detailed notes on our sampling approach, please see:
https://github.com/worldbank/GEPD/blob/develop/Data/Jordan/2019/Sampling/Sampling_Notes_Jordan.html
and

https://github.com/worldbank/GEPD/blob/develop/Data/Jordan/2019/Sampling/SamplingStrata_v2.R

### Mozambique  Specific Comments

Our sampled schools come from the list of schools surveyed by the 2018 SDI survey.  Because we were supplementing data that was collected as part of the 2018 SDI, we chose from among the schools sampled for this survey.  For public officials, the sampling was similar as described above.

To see more detailed notes on our sampling approach, please see:
https://github.com/worldbank/GEPD/blob/develop/Data/Mozambique/2019/Code/Sampling_Notes_Mozambique.html

and

https://github.com/worldbank/GEPD/blob/develop/Data/Mozambique/2019/Code/SamplingStrata_Mozambique.R

### Rwanda Specific Comments

In order to visit two schools per day, we clustered at the sector level choosing two schools per cluster.  With a sample of 200 schools, this means that we had to allocate 100 PSUs.  We combined this clustering with stratification by district and by the urban rural status of the schools.  The number of PSUs allocated to each stratum is proportionate to the number of schools in each stratum (i.e. the district X urban/rural status combination).  


To see more detailed notes on our sampling approach, please see:
https://github.com/worldbank/GEPD/blob/develop/Data/Rwanda/2019/Data/Sampling/Sampling_Notes.html

and

https://github.com/worldbank/GEPD/blob/develop/Data/Rwanda/2019/Data/Sampling/SamplingStrata.R

### Punjab Specific Comments
The survey in Pubjab is a combined effort of the Early Learning Partnership project and of the Global Education Policy Dashboard project.  

Overall, we draw a sample of 200 public schools, 200 private schools and 200 public-private partnership (PPP) schools.  We  stratified by urban/rural.  

At this stage it is important to note, that there are certain districts which we may not be able to visit due to security concerns, these are:

* Mianwali
* Dera Ghazi Khan (DG Khan)
* Rajan Pur
* Bhakkar

We have removed these districts from the sampling frame.  

Out of the 200 public schools to be surveyed we would like approximately 100 of these schools to be schools that are meeting ECE quality standards (in the data set this corresponds to public_strata==1).  Out of the remaining public schools to be sampled, 50 schools will be schools that have ECE but do not meet quality standards (public_strata==2) and 50 will be schools that have no ECE at all, and have only have katchi classes (public_strata==3). 




Due to operational constraints, we did not draw a random sample of all schools at province level.  We selected six districts for the survey (out of 32).   The survey team drew a convenience sample of 6 districts that is representative of North, Central and South Punjab, which includes both richer and poorer districts. A convenience sample was appropriate due to security and operational constraints of working in Punjab. The selected districts were:

* Attock
* Faisalabad
* Lahore 
* Muzaffargarh 
* Rahimyar Khan
* Sargodha  

In order to deal with potential refusals and closed schools, a set of replacement schools was also drawn. Within the final strata, schools were sampled proportional to size (number of total enrolled children in pre-primary). 

To see more detailed notes on our sampling approach, please see:
https://github.com/worldbank/GEPD/blob/develop/Data/Pakistan_Punjab/2019/Code/Sampling/Sampling_Notes_Punjab.html

and

https://github.com/worldbank/GEPD/blob/develop/Data/Pakistan_Punjab/2019/Code/Sampling/SamplingStrata.R

## Power Considerations

In order to assess the likely detectable effect sizes for some of our key indicators, we incorporated data from previous surveys that used a similar methodology as the Global Education Policy Dashboard.  We examined the likely detectable effect sizes for the following indicators: absenteeism, teacher content knowledge, 4th grade student knowledge, Early Childhood Development, and Teacher pedagogical skills.  



For absenteeism, we used data previously collected as part of the Service Delivery Indicators (SDI) survey (https://www.sdindicators.org/).  Data came from the countries of Afghanistan (SABER SD), Tanzania, Kenya, Mozambique, Nigeria, Uganda, and Senegal.  In each country, data on teacher presence was collected using a very similar questionnaire.  One difference is that for the SDI survey absence was collected during a second unannounced visit to the school.  In our case, we notify the school that a team of enumerators will be coming by the school over a two week period, but do not give them the exact day.  Setting aside this difference, we were able to calculate the intra-class correlation (ICC) in absence for teachers within the same school for each country and using these ICCs exame expected detectable effect sizes by # of schools sampled.  With a benchmark of around 200 schools, we expected to detect differences between two years of between 0.06-0.08 percentage points in absenteeism.

![](C:/Users/wb469649/Documents/Github/GEPD/Technical_Note/absence_power_schools.png)

For teacher content knowledge, we used the same data sources and a similar methodology.  Assuming a range of intra-class correlations which were found in previous SDI countries, we expected to detect a change in Teacher Content Knowledge of better than 0.05 standard deviations of teacher knowledge over two years.


![](C:/Users/wb469649/Documents/Github/GEPD/Technical_Note/know_power_schools.png)


For our 1st grade assessment, we used direct assessment data from the MELQO survey of Kindergarten students in four countries: Ethiopia, Peru, Mongolia, and Tanzania.  ICCs for these countries ranged from 0.05 in Mongolia to 0.43 in Tanzania.  Assuming a sample size of 200, we would expect to detect a change in Early Learner Knowledge of around 0.14 -0.2 standard deviations.

![](C:/Users/wb469649/Documents/Github/GEPD/Technical_Note/ecd_power_schools.png)
Finally, for teacher pedagogical skills, we used prior data from the TEACH survey in Mozambique and the Punjab province of Pakistan.  Based on data from these countries, we expected to detect a change in Teacher Pedagogy of around 0.16-0.18 units on the 1-5 scale of teacher pedagogical performance using our sample of 200 schools.  
![](C:/Users/wb469649/Documents/Github/GEPD/Technical_Note/teach_power_schools.png)


```{r confidence_intervals_peru, message=FALSE, warning=FALSE, include=FALSE}

peru_stats<-read_csv("C:/Users/wb469649/Documents/Github/GEPD/Technical_Note/Global Education Policy DashboardGEPD Data Explorer-Peru.csv") %>%
  select(-c("Ratio of Rural to Urban")) %>%
  rename(CI=4)

Jordan_stats<-read_csv("C:/Users/wb469649/Documents/Github/GEPD/Technical_Note/Global Education Policy DashboardGEPD Data Explorer-Jordan.csv") %>%
  select(-c("Ratio of Rural to Urban")) %>%
  rename(CI=4)

Rwanda_stats<-read_csv("C:/Users/wb469649/Documents/Github/GEPD/Technical_Note/Global Education Policy DashboardGEPD Data Explorer-Rwanda.csv") %>%
  select(-c("Ratio of Rural to Urban")) %>%
  rename(CI=4)




```


```{r confidence_intervals, message=FALSE, warning=FALSE, include=FALSE}

#create subset with just main indicators
indicators_list<-c('student_proficient',
                   'student_attendance', 
                   'presence_rate',
                   'content_proficiency', 
                   'teach_prof',
                   'ecd_student_proficiency', 
                   'inputs', 
                   'infrastructure',
                   'operational_management', 
                   'instructional_leadership',
                   'principal_knowledge_score',
                   'principal_management', 
                   'teacher_attraction', 
                   'teacher_selection_deployment', 
                   'teacher_support', 
                   'teaching_evaluation', 
                   'teacher_monitoring',
                   'intrinsic_motivation', 
                   'standards_monitoring',
                   'sch_monitoring', 
                   'sch_management_clarity',
                   'sch_management_attraction', 
                   'sch_selection_deployment', 
                   'sch_support', 
                   'principal_evaluation', 
                   'national_learning_goals',
                   'mandates_accountability',
                   'quality_bureaucracy',
                   'impartial_decision_making'
)


main_indicator_labels2<-c('Proficiency on GEPD Assessment', 
                          'Student Attendance',
                          'Teacher Effort', 
                          "Teacher Content Knowledge", 
                          "Teacher Pedagogical Skills",
                          'Capacity for Learning', 
                          'Basic Inputs', 
                          'Basic Infrastructure', 
                          'Operational Management', 
                          'Instructional Leadership', 
                          'Principal Knowledge of School',
                          'Principal Management Skills', 
                          'Policy Lever (Teaching) - Attraction',
                          'Policy Lever (Teaching) - Selection & Deployment',
                          'Policy Lever (Teaching) - Support', 
                          'Policy Lever (Teaching) - Evaluation', 
                          'Policy Lever (Teaching) - Monitoring & Accountability', 
                          'Policy Lever (Teaching) - Intrinsic Motivation', 
                          'Policy Lever (Inputs & Infrastructure) - Standards',
                          'Policy Lever (Inputs & Infrastructure) - Monitoring',
                          "Policy Lever (School Management) - Clarity of Functions", 
                          'Policy Lever (School Management) - Attraction' ,                   
                          'Policy Lever (School Management) - Selection & Deployment'  ,      
                          'Policy Lever (School Management) - Support' ,                      
                          'Policy Lever (School Management) - Evaluation'    , 
                          'Politics & Bureaucratic Capacity - National Learning Goals' ,
                          'Politics & Bureaucratic Capacity - Mandates & Accountability'   ,  
                          'Politics & Bureaucratic Capacity - Quality of Bureaucracy'    ,    
                          'Politics & Bureaucratic Capacity - Impartial Decision-Making'    
                          
                          
) 


labels_df_2<-data.frame(indicators=as.character(indicators_list),
                        indicator_labels=as.character(main_indicator_labels2))
##########################


#####
#### Peru
#####
load("//wbgfscifs01/GEDEDU/datalib-edu/projects/GEPD/CNT/PER/PER_2019_GEPD/PER_2019_GEPD_v01_M/Data/School/school_indicators_data_anon.RData")


#teacher absence
df_presence_rate <- school_dta_short_anon %>% 
  left_join(school_weights_anon ) %>% 
  mutate(ipw=if_else(is.na(abs_weight_component),ipw, ipw*abs_weight_component)) %>% 
  mutate(STRATUM=if_else(STRATUM==24,17,as.numeric(STRATUM))) %>%
  as_survey_design(ids = hashed_school_code, strata=STRATUM, weights=ipw ) %>%
  summarise(Mean = survey_mean(presence_rate, vartype = "ci", na.rm=T)) %>%
  mutate(indicators='presence_rate')

#content knowledge
df_content_proficiency <- teacher_assessment_dta_anon %>% 
  left_join(school_weights_anon ) %>% 
  mutate(ipw=if_else(is.na(teacher_weight_component),ipw, ipw*teacher_weight_component)) %>% 
  mutate(STRATUM=if_else((STRATUM==24|is.na(STRATUM)),17,as.numeric(STRATUM)),
         hashed_school_code=if_else(is.na(hashed_school_code),'abcde',hashed_school_code),
         ipw=if_else(is.na(ipw), median(ipw, na.rm=T), ipw),
         content_knowledge=if_else(is.na(literacy_content_knowledge), math_content_knowledge, literacy_content_knowledge),
         content_proficiency=100*as.numeric(content_knowledge>=80)) %>%
  as_survey_design(ids = hashed_school_code, strata=STRATUM, weights=ipw ) %>%
  summarise(Mean = survey_mean(content_proficiency, vartype = "ci", na.rm=T)) %>%
  mutate(indicators='content_proficiency')

#1st grade assessment
df_ecd_student_proficiency <- ecd_dta_anon_anon   %>% 
  left_join(school_weights_anon ) %>% 
  mutate(ipw=if_else(is.na(g1_stud_weight_component),ipw, ipw*g1_stud_weight_component)) %>% 
  mutate(STRATUM=if_else((STRATUM==24|STRATUM==5|STRATUM==22),17,as.numeric(STRATUM))) %>%
  as_survey_design(ids = hashed_school_code, strata=STRATUM, weights=ipw ) %>%
  summarise(Mean = survey_mean(ecd_student_proficiency, vartype = "ci", na.rm=T)) %>%
  mutate(indicators='ecd_student_proficiency')



#create combined dataset
if (exists('sumstats_school_df')) {
  rm('sumstats_school_df')
}

for (i in indicators_list) {
  if (exists(paste('df',i, sep="_"))) {
    #form temp data frame with each  data
   
    if (!exists('sumstats_school_df')) {
      temp <- get(paste('df',i, sep="_")) 
    
      sumstats_school_df<-temp
    } else {
    temp <- get(paste('df',i, sep="_")) 
    sumstats_school_df <- sumstats_school_df %>%
      bind_rows(temp)
    }
  } 
}

  #add variable label
  peru_stats <- sumstats_school_df %>%
    left_join(labels_df_2) %>%
    mutate(varlabel=indicator_labels) %>%
    mutate(CI=paste("[",round(Mean_low,2),", ", round(Mean_upp,2),"]", sep="")) %>%
    select(varlabel, Mean, CI)


#####
#### Jordan
#####
load("//wbgfscifs01/GEDEDU/datalib-edu/projects/GEPD/CNT/JOR/JOR_2019_GEPD/JOR_2019_GEPD_v01_M/Data/School/school_indicators_data_anon.RData")


#teacher absence
df_presence_rate <- school_dta_short_anon %>%
  left_join(school_weights_anon ) %>%
  mutate(ipw=if_else(is.na(abs_weight_component),ipw, ipw*abs_weight_component)) %>%
  as_survey_design(ids = hashed_school_code, strata=c('governorate', 'foundation_period', 'supervisory_authority'), weights=ipw ) %>%
  summarise(Mean = survey_mean(presence_rate, vartype = "ci", na.rm=T)) %>%
  mutate(indicators='presence_rate')

#content knowledge
df_content_proficiency <- teacher_assessment_dta_anon %>%
  left_join(school_weights_anon ) %>%
  mutate(ipw=if_else(is.na(teacher_weight_component),ipw, ipw*teacher_weight_component)) %>%
  mutate(

         ipw=if_else(is.na(ipw), median(ipw, na.rm=T), ipw),
         content_knowledge=if_else(is.na(literacy_content_knowledge), math_content_knowledge, literacy_content_knowledge),
         content_proficiency=100*as.numeric(content_knowledge>=80)) %>%
  as_survey_design(ids = hashed_school_code, strata=c('governorate', 'foundation_period', 'supervisory_authority'), weights=ipw ) %>%
  summarise(Mean = survey_mean(content_proficiency, vartype = "ci", na.rm=T)) %>%
  mutate(indicators='content_proficiency')

#1st grade assessment
df_ecd_student_proficiency <- ecd_dta_anon_anon   %>%
  left_join(school_weights_anon ) %>%
  mutate(ipw=if_else(is.na(g1_stud_weight_component),ipw*median(g1_stud_weight_component, na.rm=T), ipw*g1_stud_weight_component)) %>%
  as_survey_design(ids = hashed_school_code, strata=c('governorate', 'foundation_period', 'supervisory_authority'), weights=ipw ) %>%
  summarise(Mean = survey_mean(ecd_student_proficiency, vartype = "ci", na.rm=T)) %>%
  mutate(indicators='ecd_student_proficiency')


#create combined dataset
if (exists('sumstats_school_df')) {
  rm('sumstats_school_df')
}

for (i in indicators_list) {
  if (exists(paste('df',i, sep="_"))) {
    #form temp data frame with each  data

    if (!exists('sumstats_school_df')) {
      temp <- get(paste('df',i, sep="_"))

      sumstats_school_df<-temp
    } else {
    temp <- get(paste('df',i, sep="_"))
    sumstats_school_df <- sumstats_school_df %>%
      bind_rows(temp)
    }
  }
}

  #add variable label
  Jordan_stats <- sumstats_school_df %>%
    left_join(labels_df_2) %>%
    mutate(varlabel=indicator_labels) %>%
    mutate(CI=paste("[",round(Mean_low,2),", ", round(Mean_upp,2),"]", sep="")) %>%
    select(varlabel, Mean, CI)




#####
#### Rwanda
#####
load("//wbgfscifs01/GEDEDU/datalib-edu/projects/GEPD/CNT/RWA/RWA_2020_GEPD/RWA_2020_GEPD_v01_M/Data/School/school_indicators_data_anon.RData")


#teacher absence
df_presence_rate <- school_dta_short_anon %>% 
  left_join(school_weights_anon ) %>% 
  mutate(ipw=if_else(is.na(abs_weight_component),ipw, ipw*abs_weight_component)) %>% 
  as_survey_design(ids = hashed_school_district, strata=hashed_school_province, weights=ipw ) %>%
  summarise(Mean = survey_mean(presence_rate, vartype = "ci", na.rm=T)) %>%
  mutate(indicators='presence_rate')

#content knowledge
df_content_proficiency <- teacher_assessment_dta_anon %>% 
  left_join(school_weights_anon ) %>% 
  mutate(ipw=if_else(is.na(teacher_weight_component),ipw, ipw*teacher_weight_component)) %>% 
  mutate(
         
         ipw=if_else(is.na(ipw), median(ipw, na.rm=T), ipw),
         content_knowledge=if_else(is.na(literacy_content_knowledge), math_content_knowledge, literacy_content_knowledge),
         content_proficiency=100*as.numeric(content_knowledge>=80)) %>%
  as_survey_design(ids = hashed_school_district, strata=hashed_school_province, weights=ipw ) %>%
  summarise(Mean = survey_mean(content_proficiency, vartype = "ci", na.rm=T)) %>%
  mutate(indicators='content_proficiency')

#1st grade assessment
df_ecd_student_proficiency <- ecd_dta_anon_anon   %>% 
  left_join(school_weights_anon ) %>% 
  mutate(ipw=if_else(is.na(g1_stud_weight_component),ipw*median(g1_stud_weight_component, na.rm=T), ipw*g1_stud_weight_component)) %>% 
  filter(!is.na(hashed_school_code))  %>%
  as_survey_design(ids = hashed_school_district, strata=hashed_school_province, weights=ipw ) %>%
  summarise(Mean = survey_mean(ecd_student_proficiency, vartype = "ci", na.rm=T)) %>%
  mutate(indicators='ecd_student_proficiency')


#create combined dataset
if (exists('sumstats_school_df')) {
  rm('sumstats_school_df')
}

for (i in indicators_list) {
  if (exists(paste('df',i, sep="_"))) {
    #form temp data frame with each  data
   
    if (!exists('sumstats_school_df')) {
      temp <- get(paste('df',i, sep="_")) 
    
      sumstats_school_df<-temp
    } else {
    temp <- get(paste('df',i, sep="_")) 
    sumstats_school_df <- sumstats_school_df %>%
      bind_rows(temp)
    }
  } 
}

  #add variable label
  Rwanda_stats <- sumstats_school_df %>%
    left_join(labels_df_2) %>%
    mutate(varlabel=indicator_labels) %>%
    mutate(CI=paste("[",round(Mean_low,2),", ", round(Mean_upp,2),"]", sep="")) %>%
    select(varlabel, Mean, CI)







```

## Validation of Power Calculations using Peru Data

We can begin to test the assumptions of our power analysis by comparing the precision implied in our power calculations to data actually collected from our Survey in Peru in 2019.  Our Peru sample is discussed in greater detail above, but briefly we visited 205 schools.  While our power analyis was primarily concerned with the detectable effect size over a two year period, we can still use data from one year of data collection to assess whether our projects were on target.  

Our power analysis aimed to assess the detectable effect size across two years.  Making an assumption that the sampling variance for our indicators is constant across time, we can project the detectable effect size under this assmption.  Let the following be the standard error of the difference in means of one of our indicators, where $\bar X_j$ is the sample mean for year j and $\hat \sigma^2_j$ is the sample variance for year j.

$SE(\bar X_1-\bar X_0)=\sqrt(\hat \sigma^2_1/N_1 + \hat \sigma^2_0/N0)$ 

and if we assume equal variances $\sigma^2_1=\sigma^2_0$ and that the sample sizes will be the same $N_1=N_2$, the our Standard Error of the difference of the means of the two samples is:

$SE(X_1-X_0)=\sqrt(2* \hat \sigma^2_0/N0)$ 



For teacher presence, we were able to assess the presence of 1461 teachers in our sampled schools.  This produced a mean presence rate of `r round(peru_stats$Mean[1],2)` and a standard error of `r round((as.numeric(substr(peru_stats$CI[1],str_length(peru_stats$CI[1])-5,str_length(peru_stats$CI[1])-1))-peru_stats$Mean[1])/1.96,2)`. Therefore the standard error for our two mean difference is just $\sqrt 2$ times this standard error.  Therefore, our standard error for our two mean difference will be `r round(2^(1/2)*(as.numeric(substr(peru_stats$CI[1],str_length(peru_stats$CI[1])-5,str_length(peru_stats$CI[1])-1))-peru_stats$Mean[1])/1.96,2)`

Finally, to determine our detectable effect, we will be able to reject the null of an identical mean for teacher presence if our presence measure in the second Peru survey exceeds plus or minus: `r round(1.96*2^(1/2)*(as.numeric(substr(peru_stats$CI[1],str_length(peru_stats$CI[1])-5,str_length(peru_stats$CI[1])-1))-peru_stats$Mean[1])/1.96,2)` percentage points from our original mean of `r round(peru_stats$Mean[1],2)` .

This actually suggests that in the case of Peru, our forecast of detectable effect sizes were too pessimistic, as we were expecting somewhere in the range of 6-8 percentage points.  This could be attributed to lower than typical intra-class correlations in Peru for presence or to improved precision resulting from our optimal stratification technique.

For teacher content knowledge, we will omit the same full exercise as with presence, but will only say that we will be able to reject the null of an identical mean for teacher content knowledge if our measure in the second Peru survey exceeds plus or minus: `r round(1.96*2^(1/2)*(as.numeric(substr(peru_stats$CI[2],str_length(peru_stats$CI[2])-5,str_length(peru_stats$CI[2])-1))-peru_stats$Mean[2])/1.96,2)` percentage points from our original mean.

For our Early Childhood assessment, can say that we will be able to reject the null of an identical mean for ECE if our measure in the second Peru survey exceeds plus or minus: `r round(1.96*2^(1/2)*(as.numeric(substr(peru_stats$CI[3],str_length(peru_stats$CI[3])-5,str_length(peru_stats$CI[3])-1))-peru_stats$Mean[3])/1.96,2)` percentage points from our original mean.

## Validation of Power Calculations using Jordan Data

We can begin to test the assumptions of our power analysis by comparing the precision implied in our power calculations to data actually collected from our Survey in Jordan in 2019.  Our Jordan sample is discussed in greater detail above, but briefly we visited 205 schools.  While our power analyis was primarily concerned with the detectable effect size over a two year period, we can still use data from one year of data collection to assess whether our projects were on target.  

Our power analysis aimed to assess the detectable effect size across two years.  Making an assumption that the sampling variance for our indicators is constant across time, we can project the detectable effect size under this assmption.  Let the following be the standard error of the difference in means of one of our indicators, where $\bar X_j$ is the sample mean for year j and $\hat \sigma^2_j$ is the sample variance for year j.

$SE(\bar X_1-\bar X_0)=\sqrt(\hat \sigma^2_1/N_1 + \hat \sigma^2_0/N0)$ 

and if we assume equal variances $\sigma^2_1=\sigma^2_0$ and that the sample sizes will be the same $N_1=N_2$, the our Standard Error of the difference of the means of the two samples is:

$SE(X_1-X_0)=\sqrt(2* \hat \sigma^2_0/N0)$ 



For teacher presence, we were able to assess the presence of 1461 teachers in our sampled schools.  This produced a mean presence rate of `r round(Jordan_stats$Mean[1],2)` and a standard error of `r round((as.numeric(substr(Jordan_stats$CI[1],str_length(Jordan_stats$CI[1])-5,str_length(Jordan_stats$CI[1])-1))-Jordan_stats$Mean[1])/1.96,2)`. Therefore the standard error for our two mean difference is just $\sqrt 2$ times this standard error.  Therefore, our standard error for our two mean difference will be `r round(2^(1/2)*(as.numeric(substr(Jordan_stats$CI[1],str_length(Jordan_stats$CI[1])-5,str_length(Jordan_stats$CI[1])-1))-Jordan_stats$Mean[1])/1.96,2)`

Finally, to determine our detectable effect, we will be able to reject the null of an identical mean for teacher presence if our presence measure in the second Jordan survey exceeds plus or minus: `r round(1.96*2^(1/2)*(as.numeric(substr(Jordan_stats$CI[1],str_length(Jordan_stats$CI[1])-5,str_length(Jordan_stats$CI[1])-1))-Jordan_stats$Mean[1])/1.96,2)` percentage points from our original mean of `r round(Jordan_stats$Mean[1],2)` .

This actually suggests that in the case of Jordan, our forecast of detectable effect sizes were too pessimistic, as we were expecting somewhere in the range of 6-8 percentage points.  This could be attributed to lower than typical intra-class correlations in Jordan for presence or to improved precision resulting from our optimal stratification technique.

For teacher content knowledge, we will omit the same full exercise as with presence, but will only say that we will be able to reject the null of an identical mean for teacher content knowledge if our measure in the second Jordan survey exceeds plus or minus: `r round(1.96*2^(1/2)*(as.numeric(substr(Jordan_stats$CI[2],str_length(Jordan_stats$CI[2])-5,str_length(Jordan_stats$CI[2])-1))-Jordan_stats$Mean[2])/1.96,2)` percentage points from our original mean.

For our Early Childhood assessment, can say that we will be able to reject the null of an identical mean for ECE if our measure in the second Jordan survey exceeds plus or minus: `r round(1.96*2^(1/2)*(as.numeric(substr(Jordan_stats$CI[3],str_length(Jordan_stats$CI[3])-5,str_length(Jordan_stats$CI[3])-1))-Jordan_stats$Mean[3])/1.96,2)` percentage points from our original mean.


## Validation of Power Calculations using Rwanda Data

We can begin to test the assumptions of our power analysis by comparing the precision implied in our power calculations to data actually collected from our Survey in Rwanda in 2019.  Our Rwanda sample is discussed in greater detail above, but briefly we visited 205 schools.  While our power analyis was primarily concerned with the detectable effect size over a two year period, we can still use data from one year of data collection to assess whether our projects were on target.  

Our power analysis aimed to assess the detectable effect size across two years.  Making an assumption that the sampling variance for our indicators is constant across time, we can project the detectable effect size under this assmption.  Let the following be the standard error of the difference in means of one of our indicators, where $\bar X_j$ is the sample mean for year j and $\hat \sigma^2_j$ is the sample variance for year j.

$SE(\bar X_1-\bar X_0)=\sqrt(\hat \sigma^2_1/N_1 + \hat \sigma^2_0/N0)$ 

and if we assume equal variances $\sigma^2_1=\sigma^2_0$ and that the sample sizes will be the same $N_1=N_2$, the our Standard Error of the difference of the means of the two samples is:

$SE(X_1-X_0)=\sqrt(2* \hat \sigma^2_0/N0)$ 



For teacher presence, we were able to assess the presence of 1461 teachers in our sampled schools.  This produced a mean presence rate of `r round(Rwanda_stats$Mean[1],2)` and a standard error of `r round((as.numeric(substr(Rwanda_stats$CI[1],str_length(Rwanda_stats$CI[1])-5,str_length(Rwanda_stats$CI[1])-1))-Rwanda_stats$Mean[1])/1.96,2)`. Therefore the standard error for our two mean difference is just $\sqrt 2$ times this standard error.  Therefore, our standard error for our two mean difference will be `r round(2^(1/2)*(as.numeric(substr(Rwanda_stats$CI[1],str_length(Rwanda_stats$CI[1])-5,str_length(Rwanda_stats$CI[1])-1))-Rwanda_stats$Mean[1])/1.96,2)`

Finally, to determine our detectable effect, we will be able to reject the null of an identical mean for teacher presence if our presence measure in the second Rwanda survey exceeds plus or minus: `r round(1.96*2^(1/2)*(as.numeric(substr(Rwanda_stats$CI[1],str_length(Rwanda_stats$CI[1])-5,str_length(Rwanda_stats$CI[1])-1))-Rwanda_stats$Mean[1])/1.96,2)` percentage points from our original mean of `r round(Rwanda_stats$Mean[1],2)` .

This actually suggests that in the case of Rwanda, our forecast of detectable effect sizes were too pessimistic, as we were expecting somewhere in the range of 6-8 percentage points.  This could be attributed to lower than typical intra-class correlations in Rwanda for presence or to improved precision resulting from our optimal stratification technique.

For teacher content knowledge, we will omit the same full exercise as with presence, but will only say that we will be able to reject the null of an identical mean for teacher content knowledge if our measure in the second Rwanda survey exceeds plus or minus: `r round(1.96*2^(1/2)*(as.numeric(substr(Rwanda_stats$CI[2],str_length(Rwanda_stats$CI[2])-5,str_length(Rwanda_stats$CI[2])-1))-Rwanda_stats$Mean[2])/1.96,2)` percentage points from our original mean.

For our Early Childhood assessment, can say that we will be able to reject the null of an identical mean for ECE if our measure in the second Rwanda survey exceeds plus or minus: `r round(1.96*2^(1/2)*(as.numeric(substr(Rwanda_stats$CI[3],str_length(Rwanda_stats$CI[3])-5,str_length(Rwanda_stats$CI[3])-1))-Rwanda_stats$Mean[3])/1.96,2)` percentage points from our original mean.

## Full Tabulation of Means and Confidence Intervals for Peru
Means and 95% Confidence Intervals are available for all of our primary indicators collected using our surveys below.

```{r eval=FALSE, include=FALSE}

#caption
peru_cap<-tab_num(name="peru_cap", caption="Summary Statistics and Confidence Intervals for Dashboard Indicators - Peru 2019")

kable(peru_stats,
      caption=peru_cap,
      col.names = c("Indicator", "Value Range", "Overall Mean", "95% CI", "Urban Mean", "95% CI", "Rural Mean", "95% CI" ))

```



## Survey Weights

Survey weights are constructed using our original sampling frame for a country.  School Weights are the inverse probability that a 4th grade student in the school is randomly selected for the school survey.  The exact formula depends on the selection procedure for choosing schools.  In nearly all cases, we use some form of stratification, in which case the probabilities referenced above are computed within each stratum.  The weight for school i within stratum j is, where m is a measure of school size and n is the number of schools selected per stratum:

$$ SW_i^j=\frac{\sum_{i=1}^{N_j}m_i}{n*m_i} $$


In a simple case where schools are selected at random proportional to size, this is calculated by summing the total number of students in each particular school and dividing by the total number of 4th grade students in the sampling frame.    In cases where we have large amounts of non-responses or refusals to enter the school, we will add an adjustment term to account for non-response.  This could happen for instance, if an originally sampled school was selected but refused and the two replacement schools for that school also refused.

For student level or teacher level data, we will also create an adjustment for the random selection of classrooms, teachers, or students that takes place within schools.  In order to form these weights at the individual level, the school weight is multiplied by the number of units sampled (five teachers for the teacher interview, 10 for the teacher absence module, one for the class of 4th graders, and three for the three randomly selected 1st grade students.).  


# Data Collection

Below, we will briefly discuss the data collection protocols and processes used by our team.  In short, we use Survey Solutions, which is a tablet based, free, open source survey tool designed by the World Bank.  The data flow then is as follows:

1. Data is collected by an enumerator  
2. The enumerator or their supervisor then uploads the collected data to our secure server (typically a server generated by the Survey Solutions team)  
3. The data is encrypted on the server  
4. The Global Education Policy Dashboard Team then downloads the encrypted data using the Survey Solutions API
5. Our data is stored in a secure folder
6. We clean the data, create unique IDs for students, teachers, principals, schools, and public officials using cryptographic hashing 
7. A number of data quality checks are run to minimize missing values, identify enumerator errors, and ensure accurate coding  
8. The data is then anonymized removing all PII information  
9. Our final indicators are then aggregated to the National level, as well as offering breakdowns by Urban/Rural and Gender  
10. This aggregated data is then uploaded to the World Bank open data platform Edstats  
11. The Global Education Policy Dashboard website then pulls the data from EdStats using the EdStats API system  


## Survey Solutions

Survey Solutions is a free, open source data collection platform designed by World Bank staff.

The raw data will be hosted on a secure server, which is certified by several dozen well known international bodies, including the EU Data Protection Directive.  More information on the certifications can be found here: https://support.mysurvey.solutions/faq/how-secure-is-the-world-bank-cloud-/. 

## Anonymization

Immediately following download of data from Survey Solutions, we remove the following and save as an anonymized version of the data:
1.Drop Enumerator name  
2. Drop school name, address, official school codes (EMIS codes)  
3. Drop principal name, phone numbers  
4. Drop Geo-code info  
5. Drop unique responses, such as when respondent is asked to specify other as a choice  

The following are produced:
1. Produce Crypto-hashed School ID, Province ID, District ID  

We convert the following variables into categorical data:
2. Respondent age
3. Year began teaching
4. Number of students in school/class
5. Top-coded variables:
6. Educational degrees


# Data Quality Checks

While survey data is collected, we run daily quality checks to ensure the data is high quality.  These include both built in checks available through the survey solutions HeadQuarters app, and also a custom designed data quality check tool.

Survey Solutions has several built in quality checks.  These include a mapping tool based on the geocoordinates enterred by the enumerators during data collection and an interview management system where supervisors or the headquarters can see whether all questions that should have been completed by the enumerator are completed.  Supervisors then have the option to send feedback to the enumerator and reject the interview until the data is sucessfully collected.

Additionally, our team has designed a set of custom tools for our Survey of Public Officials and School Survey.  All code for our data quality checks can be found on our Global Education POlicy Dashboard github site (https://github.com/worldbank/GEPD).  These tools allow the field team to calculate our final primary indicators in real time and check for any anomalies including missing values, data enterred at strange times (e.g. after regular business hours), and to look at data collected for specific enumerators.

# Indicator Construction

```{r echo=FALSE, message=FALSE, warning=FALSE}

indicators_dir <- "C:/Users/wb469649/Documents/Github/GEPD/Indicators/"

    #Get metadata from github
    indicator_choices<-read_delim(paste(indicators_dir, 'indicators_choices.md',sep=""), delim="|", trim_ws=TRUE)
    
    names(indicator_choices)<-make.names(names(indicator_choices), unique=TRUE)
    
    indicator_choices <- indicator_choices %>%
      select(-X1, -X6) %>%
      filter(Series!="---")
    
  #produce caption for table
  indicator_choices_captioner<-tab_num(name="indicator_choices_cap", caption="High Level Description of How Each Indicator is Scored")
  
  #Produce table
  indicator_choices %>% 
    select(Indicator.Name, Value, How.is.the.indicator.scored.) %>%
    kable(caption=indicator_choices_captioner,
          col.names =c( "Indicator Name", "Values", "How Indicator is Scored")) 

```





# Appendix

## Detailed Indicator Construction

Below is a list of the primary indicators and sub-indicators used to construct our final indicators.

```{r subindicators, echo=FALSE}
# 
#  ind_list <-c('student_knowledge', 
#                 'math_student_knowledge', 
#                 'literacy_student_knowledge', 
#                 'student_proficient', 
#                 'literacy_student_proficient', 
#                 'math_student_proficient', 
#                 'student_proficient_70',  
#                 'student_proficient_75',
#              'student_attendance',
#              'presence_rate',  
#              'absence_rate', 
#              'school_absence_rate', 
#              'content_proficiency', 
#              'literacy_content_proficiency', 
#              'math_content_proficiency', 
#              'content_proficiency_70', 
#              'content_proficiency_75', 
#              'content_knowledge', 
#              'math_content_knowledge', 
#              'literacy_content_knowledge', 
#              'grammar', 
#              'cloze',  
#              'read_passage', 
#              'arithmetic_number_relations', 
#              'geometry', 
#              'interpret_data',
#              'ecd_student_knowledge', 
#              'ecd_math_student_knowledge', 
#              'ecd_literacy_student_knowledge', 
#              'ecd_exec_student_knowledge', 
#              'ecd_soc_student_knowledge',
#              'ecd_student_proficiency', 
#              'ecd_math_student_proficiency',
#              'ecd_literacy_student_proficiency', 
#              'ecd_exec_student_proficiency', 
#              'ecd_soc_student_proficiency',
#              'inputs', 
#              'blackboard_functional', 
#              'pens_etc',
#              'textbooks', 
#              'share_desk', 
#              'used_ict', 
#              'access_ict',
#              'infrastructure',
#              'drinking_water', 
#              'functioning_toilet', 
#              'internet', 
#              'class_electricity',
#              'disability_accessibility',
#              'operational_management',
#              'vignette_1', 
#              'vignette_2', 
#              'intrinsic_motivation', 
#              'acceptable_absent', 
#              'students_deserve_attention', 
#              'growth_mindset', 
#              'motivation_teaching',
#              'instructional_leadership', 
#              'classroom_observed', 
#              'classroom_observed_recent', 
#              'discussed_observation', 
#              'feedback_observation', 
#              'lesson_plan_w_feedback',
#              'principal_knowledge_score', 
#              'add_triple_digit_pknw', 
#              'multiply_double_digit_pknw', 
#              'complete_sentence_pknw', 
#              'experience_pknw', 
#              'textbooks_pknw', 
#              'blackboard_pknw',
#              'principal_management', 
#              'school_goals_exist',
#              'school_goals_clear',
#              'school_goals_relevant',
#              'school_goals_measured',
#              'teacher_attraction', 
#              'teacher_satisfied_job', 
#              'teacher_satisfied_status', 
#              'better_teachers_promoted' ,
#              'teacher_bonus', 
#              'salary_delays',
#              'teacher_selection_deployment', 
#              'teacher_selection',
#              'teacher_deployment',
#              'teacher_support', 
#              'pre_service',
#              'practicum',
#              'in_service',
#              'opportunities_teachers_share',
#              'teaching_evaluation', 
#              'formally_evaluated', 
#              'evaluation_content', 
#              'negative_consequences',
#              'positive_consequences',
#              'teacher_monitoring',
#              'attendance_evaluated' ,
#              'attendance_rewarded' , 
#              'attendence_sanctions', 
#              'miss_class_admin',
#              'standards_monitoring',
#              'school_monitoring', 
#              'monitoring_inputs',
#              'monitoring_infrastructure',
#              'parents_involved',
#              'school_management_clarity', 
#              'infrastructure_scfn',
#              'materials_scfn',
#              'hiring_scfn', 
#              'supervision_scfn', 
#              'student_scfn' , 
#              'principal_hiring_scfn', 
#              'principal_supervision_scfn',
#              'school_management_attraction', 
#              'principal_satisfaction', 
#              'principal_salary',
#              'school_selection_deployment', 
#              'school_support', 
#              'prinicipal_trained',
#              'principal_training',
#              'principal_used_skills',
#              'principal_offered',
#              'principal_evaluation', 
#              'principal_formally_evaluated',
#              'principal_evaluation_multiple',
#              'principal_negative_consequences',
#              'principal_positive_consequences',
#              'national_learning_goals', 
#              'targeting', 
#              'monitoring', 
#              'incentives', 
#              'community_engagement',
#              'mandates_accountability' , 
#              'coherence', 
#              'transparency', 
#              'accountability', 
#              'quality_bureaucracy', 
#              'knowledge_skills', 
#              'work_environment', 
#              'merit', 
#              'motivation_attitudes',
#              'motivation_relative_start',
#              'impartial_decision_making',
#              'politicized_personnel_management',
#              'politicized_policy_making', 
#              'politicized_policy_implementation', 
#              'employee_unions_as_facilitators'
#  )
#  
#  indicator_labels<-c("4th Grade Student Knowledge", 
#                      "4th Grade Math Knowledge", 
#                      "4th Grade Literacy Knowledge", 
#                      "4th Grade Student Proficiency", 
#                      "4th Grade Student Proficiency Literacy",
#                      "4th Grade Student Proficiency Math",
#                      "4th Grade Student Proficiency at 70% threshold",  
#                      "4th Grade Student Proficiency at 75% threshold",
#                      "Student Attendance Rate",
#                      "Teacher Classroom Presence Rate ", 
#                      "Teacher Classroom Absence Rate ", 
#                      "Teacher School Absence Rate", 
#                      "Teacher Content Proficiency", 
#                      "Teacher Content Proficiency Literacy", 
#                      "Teacher Content Proficiency Math", 
#                      "Teacher Content Proficiency at 70% threshold", 
#                      "Teacher Content Proficiency at 75% threshold", 
#                      "Teacher Content Knowledge", 
#                      "Teacher Math Content Knowledge", 
#                      "Teacher Literacy Content Knowledge", 
#                      'Grammar', 
#                      'Cloze Task',  
#                      'Read Passage', 
#                      'Arithmetic & Number Relations', 
#                      'Geometry', 
#                      'Interpret Data',
#                      "1st Grade Assessment Score", 
#                      "1st Grade Numeracy Score", 
#                      "1st Grade Literacy Score", 
#                      "1st Grade Executive Functioning Score", 
#                      "1st Grade Socio-Emotional Score",
#                      "1st Grade Assessment Proficiency", 
#                      "1st Grade Numeracy Proficiency", 
#                      "1st Grade Literacy Proficiency", 
#                      "1st Grade Executive Functioning Proficiency", 
#                      "1st Grade Socio-Emotional Proficiency",
#                      "Inputs", 
#                      "Functioning Blackboard (Based on classroom observation: Is there a blackboard, Is there chalk, and Is there sufficient light", 
#                      "Classroom Materials (Pens, Pencils, Exercise Books)", 
#                      "Textbooks", 
#                      "Desks", 
#                      "ICT Usage", 
#                      "ICT Access",
#                      "Infrastructure", 
#                      "Clean Drinking Water", 
#                      "Functioning Toilets", 
#                      "Internet", 
#                      "Electricity", 
#                      "Disability Accessibility", 
#                      "Operational Management", 
#                      "Operational Management - Vignette 1",  
#                      "Operational Management - Vignette 2",
#                      "Teacher Intrinsic Motivation", 
#                      'Scores on set of questions to teachers on whether it is ever acceptable to be absent', 
#                      'Scores on set of questions to teachers on whether some students deserve more attention than others', 
#                      'Scores on questions related to growth mindset', 
#                      'Motivation to teach based on whether teacher joined teaching just for job security',
#                      "Instructional Leadership", 
#                      'Whether or not classroom has been observed', 
#                      'Whether observation took place in last 12 months', 
#                      'Whether teacher discussed classroom observation with principal/head teacher', 
#                      'Whehter feedback was given on classroom observation and converation lasted more than 30 min', 
#                      'Whether teacher had feedback on lesson plan',
#                      'Principal Knowledge of School', 
#                      'Correct on # of Teachers correct on Triple Digit Addition', 
#                      'Correct on # of Teachers correct on Double Digit Multiplication', 
#                      'Correct on # of Teachers correct on Completing Sentence Question', 
#                      'Correct on # of Teachers Under 3 Years Experience', 
#                      'Correct on # of Students with Textbooks ', 
#                      'Correct on Functional Blackboard',
#                      'Principal Management Skills', 
#                      'According to Principal: School Goals Exist',
#                      'According to Principal:  to Principal: School Goals Clear',
#                      'According to Principal: School Goals Relevant',
#                      'According to Principal: School Goals Measured',
#                      'Teacher Attraction (De Facto)', 
#                      'Teacher Satisfied with Job', 
#                      'Teachers Satisfied with Status in Community', 
#                      'Teacher perceives that better teachers more likely to be promoted' ,
#                      'Teacher received bonus in past year', 
#                      'Salary Delays reported by teacher',
#                      'Teacher Selection & Deployment (De Facto)', 
#                      'Teacher recruited based on passing written content knowledge test, passed interview stage assessment, passed an assessment conducted by supervisor based on practical experience, conduct during mockup class',
#                      'Teacher deployed based on performance assessed by school authority, colleagues, or external evaluator, results of interview.',
#                      'Teacher Support (De Facto)', 
#                      'Had pre-service training and teacher reported finding it useful',
#                      'Had a practicum and training lasted multiple days',
#                      'Had in-service training that lasted more than 2 days and had a component that took place in classroom ',
#                      'Whether teacher reported having opportunities to come together and share ways of improving teaching',
#                      'Teacher Evaluation (De Facto)', 
#                      'Teacher reported being formally evaluated', 
#                      'Evaluation had multiple components', 
#                      'Teacher reported negative consequences would occur if received 2 or more negative evaluations',
#                      'Teacher reported positive consequences would occur if received 2 or more positive evaluations',
#                      'Teacher Monitoring & Accountability (De Facto)', 
#                      'Teachers evaluated by some authority on basis of absence' , 
#                      'Teacher reported good attendance is rewarded. ' , 
#                      'Teacher reported there are consequences for chronic absence (more than 30% absence)', 
#                      'Teacher reported having to miss class for administrative reasons',
#                      'Inputs and Infrastructure Standards',
#                      "Inputs and Infrastructure Monitoring", 
#                      'Fraction of inputs Principal reported being monitored (functioning blackboard, chalk, pens, pencils, textbooks, exercise books in 4th grade classrooms, basic classroom furniture, and at least one computer in the schools)',
#                      'Fraction of infrastructure elements Principal reported being monitored (functioning toilets, electricity, drinking water, and accessibility for people with disabilities)',
#                      'Principal reports community involved in the monitoring',
#                      "School Management Clarity of Functions", 
#                      'Do you know if the policies governing schools assign responsibility for the implementation of each of the following: Maintenance of Infrastructure',
#                      'Do you know if the policies governing schools assign responsibility for the implementation of each of the following: Procurement of materials',
#                      'Do you know if the policies governing schools assign responsibility for the implementation of each of the following: Teacher hiring and assignment', 
#                      'Do you know if the policies governing schools assign responsibility for the implementation of each of the following: Teacher supervision, training, and coaching', 
#                      'Do you know if the policies governing schools assign responsibility for the implementation of each of the following: Student Learning Assessments' , 
#                      'Do you know if the policies governing schools assign responsibility for the implementation of each of the following: Principal hiring and assignment', 
#                      'Do you know if the policies governing schools assign responsibility for the implementation of each of the following: Principal Supervision and training',
#                      "School Management Attraction", 
#                      'Principal satisfied with status in community', 
#                      'Principal reported salary as fraction of GDP',
#                      "School Management Selection & Deployment",
#                      "School Management Support", 
#                      'Principal reported receiving formal training on managing school',
#                      'Principal had received the following training (1/3 point for each): Management training for new principals, in-service training, mentoring coaching',
#                      'Principal reported using skills from training',
#                      'Principal reported offered training at least once per year',
#                      "School Management Evaluation", 
#                      'Principal reported being formally evaluated',
#                      'Principal evaluation based on multiple components (at least 5 components for full credit',
#                      'Principal reported negative consequences would occur if received 2 or more negative evaluations',
#                      'Principal reported negative consequences would occur if received 2 or more negative evaluations',
#                      "National Learning Goals", 'Targeting', 'Monitorinig', 'Incentives', 'Community Engagement',
#                      "Mandates and Accountability", 'Coherence', 'Transparency', 'Accountability of Public Officials',
#                      "Quality of Bureaucracy", 'Knowledge and Skills', 'Work Environment', 'Merit', 'Motivation and Attitudes', 'Motivation Relative to Starting Public Service',
#                      "Impartial Decision Making", 'Politicized personnel management', 'Politicized policy-making', 'Politicized policy-implementation', 'Employee unions as facilitators'
#  )
#  
#  indicator_module<-c("4th Grade Student Assessment", 
#                      "4th Grade Student Assessment", 
#                      "4th Grade Student Assessment",  
#                      "4th Grade Student Assessment", 
#                      "4th Grade Student Assessment", 
#                      "4th Grade Student Assessment", 
#                      "4th Grade Student Assessment",   
#                      "4th Grade Student Assessment", 
#                      "Student Roster and Classroom Observation",
#                      "Teacher Roster and School Inspection", 
#                      "Teacher Roster and School Inspection", 
#                      "Teacher Roster and School Inspection", 
#                      "Teacher Assessment", 
#                      "Teacher Assessment", 
#                      "Teacher Assessment", 
#                      "Teacher Assessment", 
#                      "Teacher Assessment",  
#                      "Teacher Assessment", 
#                      "Teacher Assessment",  
#                      "Teacher Assessment",  
#                      "Teacher Assessment",  
#                      "Teacher Assessment",   
#                      "Teacher Assessment",  
#                      "Teacher Assessment",  
#                      "Teacher Assessment", 
#                      "Teacher Assessment", 
#                      "1st Grade Direct Assessment", 
#                      "1st Grade Direct Assessment",
#                      "1st Grade Direct Assessment", 
#                      "1st Grade Direct Assessment", 
#                      "1st Grade Direct Assessment",
#                      "1st Grade Direct Assessment",
#                      "1st Grade Direct Assessment", 
#                      "1st Grade Direct Assessment",
#                      "1st Grade Direct Assessment", 
#                      "1st Grade Direct Assessment",
#                      "Classroom Observation", 
#                      "Classroom Observation",
#                      "Classroom Observation", 
#                      "Classroom Observation",
#                      "Classroom Observation", 
#                      "Teacher Inverview", 
#                      "School Inspection",
#                      "School Inspection", 
#                      "School Inspection",
#                      "School Inspection", 
#                      "School Inspection",  
#                      "School Inspection",  
#                      "School Inspection",  
#                      "Principal Interview", 
#                      "Principal Interview",   
#                      "Principal Interview", 
#                      "Teacher Interview", 
#                      "Teacher Interview",  
#                      "Teacher Interview", 
#                      "Teacher Interview",  
#                      "Teacher Interview", 
#                      "Teacher Interview",  
#                      "Teacher Interview", 
#                      "Teacher Interview",  
#                      "Teacher Interview", 
#                      "Teacher Interview",  
#                      "Teacher Interview", 
#                      'Principal Interview', 
#                      'Principal Interview', 
#                      'Principal Interview',
#                      'Principal Interview', 
#                      'Principal Interview',
#                      'Principal Interview',
#                      'Principal Interview',
#                      'Principal Interview', 
#                      'Principal Interview',
#                      'Principal Interview',
#                      'Principal Interview',
#                      'Principal Interview',
#                      'Teacher Interview', 
#                      'Teacher Interview', 
#                      'Teacher Interview', 
#                      'Teacher Interview',
#                      'Teacher Interview',
#                      'Teacher Interview',
#                      'Teacher Interview',
#                      'Teacher Interview',
#                      'Teacher Interview',
#                      'Teacher Interview', 
#                      'Teacher Interview',
#                      'Teacher Interview',
#                      'Teacher Interview',
#                      'Teacher Interview',
#                      'Teacher Interview',
#                      'Teacher Interview',
#                      'Teacher Interview',
#                      'Teacher Interview',
#                      'Teacher Interview',
#                      'Teacher Interview', 
#                      'Teacher Interview',
#                      'Teacher Interview',
#                      'Teacher Interview', 
#                      'Teacher Interview',
#                      'Principal Interview',
#                      'Principal Interview',
#                      'Principal Interview',
#                      'Principal Interview',
#                      'Principal Interview',
#                      'Principal Interview',
#                      'Principal Interview',
#                      'Principal Interview',
#                      'Principal Interview',
#                      'Principal Interview',
#                      'Principal Interview', 
#                      'Principal Interview',
#                      'Principal Interview',
#                     'Principal Interview',
#                      'Principal Interview', 
#                      'Principal Interview',
#                      'Principal Interview',
#                      'Principal Interview',
#                      'Principal Interview',
#                      'Principal Interview',
#                      'Principal Interview',
#                      'Principal Interview',
#                      'Principal Interview', 
#                      'Principal Interview',
#                      'Principal Interview',
#                      'Principal Interview',
#                      'Principal Interview',
#                      "Public Official Interview", 'Public Official Interview', 'Public Official Interview', 'Public Official Interview', 'Public Official Interview',
#                      "Public Official Interview", 'Public Official Interview', 'Public Official Interview', 'Public Official Interview',
#                      "Public Official Interview", 'Public Official Interview', 'Public Official Interview', 'Public Official Interview', 'Public Official Interview', 'Public Official Interview',
#                      "Public Official Interview", 'Public Official Interview', 'Public Official Interview', 'Public Official Interview', 'Public Official Interview'
#  ) 
#  
#  
#   survey_det<-c("Fraction correct on our 4th grade assessment", 
#                      "Fraction correct on our 4th grade math assessment", 
#                      "Fraction correct on our 4th grade language assessment", 
#                      "Whether or not student reached 34/41 items correct", 
#                      "Whether or not student reached 20/24 items correct",
#                      "Whether or not student reached 14/17 items correct",
#                      "4th Grade Student Proficiency at 70% threshold",  
#                      "4th Grade Student Proficiency at 75% threshold",
#                      "# of students present divided by # according to class list",
#                      "Fraction of teachers out of 10 that were in class and school during attendance check", 
#                      "Fraction of teacher not in class or school during attendance check", 
#                      "Fraction of teacher not in school during attendance check", 
#                      "Fraction of teachers scoring 80% of higher on overall content assessment", 
#                      "Fraction of teachers scoring 80% of higher on literacy content assessment", 
#                      "Fraction of teachers scoring 80% of higher on math content assessment", 
#                      "Teacher Content Proficiency at 70% threshold", 
#                      "Teacher Content Proficiency at 75% threshold", 
#                      "Average score at school level on math and literacy portion of content exam", 
#                      "Fraction correct on overall math assessment", 
#                      "Fraction correct on overall literacy assessment", 
#                      'Fraction correct on grammar task of content assessment', 
#                      'Fraction correct on cloze task of content assessment',  
#                      'Fraction correct on read a passage task of content assessment', 
#                      'Fraction correct on arithmetic and number relations task of content assessment', 
#                      'Fraction correct on geometry task of content assessment', 
#                      'Fraction correct on interpretting data task of content assessment',
#                      "Average of the fraction correct in numeracy, literacy, socio-emotional, and executive functioning", 
#                      "1st Grade Numeracy Fraction Correct", 
#                      "1st Grade Literacy Fraction Correct", 
#                      "1st Grade Executive Functioning Fraction Correct", 
#                      "1st Grade Socio-Emotional Fraction Correct",
#                      "Marked as proficient if student could score at least 80% of items correct", 
#                      "Marked as proficient if student could score at least 90% of math items correct", 
#                      "Marked as proficient if student could score at least 80% of literacyitems correct", 
#                      "Marked as proficient if student could score at least 70% of executive functiong items correct", 
#                      "Marked as proficient if student could score at least 80% of socio-emotional items correct",
#                      "Total of whether there is functional blackboard, materials, desks, and ICT", 
#                      "Functioning Blackboard (Based on classroom observation: Is there a blackboard, Is there chalk, and Is there sufficient light", 
#                      "# of Classroom Materials (Pens, Pencils, Exercise Books) divided by # of students in class", 
#                      "# of Classroom  Textbooks divided by # of students in class", 
#                      "# of Classroom  Desks divided by # of students in class", 
#                      "Whether or not teacher reported using ICT", 
#                      "Whether tablets/computers were working and had internet connectivity",
#                      "Infrastructure", 
#                      "Enumerators assess whether water comes from piped water, protected well, packaged bottle water, or tanker truck.  No credit for unprotected sources", 
#                      "Toilets exist, separate for boys/girls, clean, private, useable,  handwashing available", 
#                      "1 point if internet working, 0.5 if doesn't work well, 0 if not at all", 
#                      "Enuermator assessment of whether electricity worked in randomly selected class", 
#                      "Accessibility from road, has ramp with accessible entrance for school and classrooms", 
#                      "Operational Management", 
#                      "Leaky roof vignette: 0.5 points are awarded for someone specific having the responsibility to fix,0.5 point is awarded if the school can fully fund the repair, 0.25 points is awarded if the school must get partial help from the community, and 0 points are awarded if the full cost must be born by the community, 1 point is awarded if the problem is fully resolved in a timely manner, with partial credit given if problem can only be partly resolved.",  
#                      "Inadequate number of textbooks vignette: 0.5 points are awarded for someone specific having the responsibility to fix,0.5 point is awarded if the school can fully address, 0.25 points is awarded if the school must get partial help from the community, and 0 points are awarded if the full cost must be born by the community, 1 point is awarded if the problem is fully resolved in a timely manner, with partial credit given if problem can only be partly resolved.",
#                      "Teacher Intrinsic Motivation", 
#                      'Scores on set of questions to teachers on whether it is ever acceptable to be absent', 
#                      'Scores on set of questions to teachers on whether some students deserve more attention than others', 
#                      'Scores on questions related to growth mindset', 
#                      'Motivation to teach based on whether teacher joined teaching just for job security',
#                      "Instructional Leadership", 
#                      'Whether or not classroom has been observed', 
#                      'Whether observation took place in last 12 months', 
#                      'Whether teacher discussed classroom observation with principal/head teacher', 
#                      'Whehter feedback was given on classroom observation and converation lasted more than 30 min', 
#                      'Whether teacher had feedback on lesson plan',
#                      'Principal Knowledge of School', 
#                      'Correct on # of Teachers correct on Triple Digit Addition', 
#                      'Correct on # of Teachers correct on Double Digit Multiplication', 
#                      'Correct on # of Teachers correct on Completing Sentence Question', 
#                      'Correct on # of Teachers Under 3 Years Experience', 
#                      'Correct on # of Students with Textbooks ', 
#                      'Correct on Functional Blackboard',
#                      'Principal Management Skills', 
#                      'According to Principal: School Goals Exist',
#                      'According to Principal:  to Principal: School Goals Clear',
#                      'According to Principal: School Goals Relevant',
#                      'According to Principal: School Goals Measured',
#                      'Teacher Attraction (De Facto)', 
#                      'Teacher Satisfied with Job', 
#                      'Teachers Satisfied with Status in Community', 
#                      'Teacher perceives that better teachers more likely to be promoted' ,
#                      'Teacher received bonus in past year', 
#                      'Salary Delays reported by teacher',
#                      'Teacher Selection & Deployment (De Facto)', 
#                      'Teacher recruited based on passing written content knowledge test, passed interview stage assessment, passed an assessment conducted by supervisor based on practical experience, conduct during mockup class',
#                      'Teacher deployed based on performance assessed by school authority, colleagues, or external evaluator, results of interview.',
#                      'Teacher Support (De Facto)', 
#                      'Had pre-service training and teacher reported finding it useful',
#                      'Had a practicum and training lasted multiple days',
#                      'Had in-service training that lasted more than 2 days and had a component that took place in classroom ',
#                      'Whether teacher reported having opportunities to come together and share ways of improving teaching',
#                      'Teacher Evaluation (De Facto)', 
#                      'Teacher reported being formally evaluated', 
#                      'Evaluation had multiple components', 
#                      'Teacher reported negative consequences would occur if received 2 or more negative evaluations',
#                      'Teacher reported positive consequences would occur if received 2 or more positive evaluations',
#                      'Teacher Monitoring & Accountability (De Facto)', 
#                      'Teachers evaluated by some authority on basis of absence' , 
#                      'Teacher reported good attendance is rewarded. ' , 
#                      'Teacher reported there are consequences for chronic absence (more than 30% absence)', 
#                      'Teacher reported having to miss class for administrative reasons',
#                      'Inputs and Infrastructure Standards',
#                      "Inputs and Infrastructure Monitoring", 
#                      'Fraction of inputs Principal reported being monitored (functioning blackboard, chalk, pens, pencils, textbooks, exercise books in 4th grade classrooms, basic classroom furniture, and at least one computer in the schools)',
#                      'Fraction of infrastructure elements Principal reported being monitored (functioning toilets, electricity, drinking water, and accessibility for people with disabilities)',
#                      'Principal reports community involved in the monitoring',
#                      "School Management Clarity of Functions", 
#                      'Do you know if the policies governing schools assign responsibility for the implementation of each of the following: Maintenance of Infrastructure',
#                      'Do you know if the policies governing schools assign responsibility for the implementation of each of the following: Procurement of materials',
#                      'Do you know if the policies governing schools assign responsibility for the implementation of each of the following: Teacher hiring and assignment', 
#                      'Do you know if the policies governing schools assign responsibility for the implementation of each of the following: Teacher supervision, training, and coaching', 
#                      'Do you know if the policies governing schools assign responsibility for the implementation of each of the following: Student Learning Assessments' , 
#                      'Do you know if the policies governing schools assign responsibility for the implementation of each of the following: Principal hiring and assignment', 
#                      'Do you know if the policies governing schools assign responsibility for the implementation of each of the following: Principal Supervision and training',
#                      "School Management Attraction", 
#                      'Principal satisfied with status in community', 
#                      'Principal reported salary as fraction of GDP',
#                      "School Management Selection & Deployment",
#                      "School Management Support", 
#                      'Principal reported receiving formal training on managing school',
#                      'Principal had received the following training (1/3 point for each): Management training for new principals, in-service training, mentoring coaching',
#                      'Principal reported using skills from training',
#                      'Principal reported offered training at least once per year',
#                      "School Management Evaluation", 
#                      'Principal reported being formally evaluated',
#                      'Principal evaluation based on multiple components (at least 5 components for full credit',
#                      'Principal reported negative consequences would occur if received 2 or more negative evaluations',
#                      'Principal reported negative consequences would occur if received 2 or more negative evaluations',
#                      "Average of Targeting, Monitoring, Incentives, and Community Engagement components", 
#                 'Questions on whether learning goals exist, are measurable, whether tasks aligned', 
#                 'Questions on how well performance goals tracked, EMIS system, how info reviewed', 
#                 'Are rewards given for high performance, rewards for excellence in contributing to learning goals, does information inform budgets', 
#                 'Most common means of getting feedback from parents, is feedback used for evaluation/budgets',
#                 "Average of coherence, transparency, accountability of public officials", 
#                 'Is organizational responsibilities clear', 
#                 'Are achievements related to performance targets made public, is transparency beneficial', 
#                 'What would happen to public officials in cases of malfeasance',
#                  "Average score of knowledge and skills, work environment, merit, movitation and attitudes", 
#                 'Public officials asked if they know numbers on average class size, teacher absences', 
#                 'Do employees trust one another, gifts to public officials, encouragement of new ideas', 
#                 'How is selection and deployment done', 
#                 'How satisfied are public officials, how motivated, is it OK for teachers to be absent, ok for some students get less attention', 
#                 'Motivation Relative to Starting Public Service',
#                 "Impartial Decision Making", 
#                 'Are hiring/promotion decisions/evaluations based on public influence', 
#                 'Are budget,procurement, curriculum decisions affected by politics?', 
#                 'What proportion of public officials broken rules, are contracts/procuements subject to politics', 
#                 'Does union membership affect teacher hiring, do public official union members get preferential treatment, are new practices influence by unions?'
#  )
#  
#  
#  labels_df<-data.frame(
#                        indicator_labels=as.character(indicator_labels),
#                        indicator_module=as.character(indicator_module),
#                        survey_det=as.character(survey_det))
#  
#  colnames(labels_df) <-  c("Variable", "How Was Data Collected?", "Details on Scoring")
 
# write_excel_csv(labels_df, path=paste(indicators_dir, 'indicators_details.csv',sep="")           )

labels_df <- read_csv(paste(indicators_dir, 'indicators_details.csv',sep=""))
 
#produce caption for table
data_desc_cap<-tab_num(name="data_desc_cap", caption="Detailed Documentation of Indicators & Sub-Indicators")
kable(labels_df,
      caption=data_desc_cap,
      col.names = c("Variable", "How Was Data Collected?", "Details on Scoring"))

```

## Details on Indicator Construction

Below we will show exact code, written in R, to produce our indicator values.  Code is lightly edited for clarity and length.

### Teacher Absence


Teacher absence is defined as whether or not the teacher was absenct from the school or classroom during an unannounced visit.  For a working example, see below.  The basis for the question is the following below:

What was the teacher doing when you located him/ her on the first visit?	
1= In classroom- teaching  
2= In classroom- not teaching  
3= At school- teaching outdoors  
4= At school not his/her shift/not her class  
5= At school- not in classroom  
6= Absent from school  


```{r absence, eval=FALSE, include=code_inclusion}

teacher_absence_ex<-teacher_roster_anon %>%
  select(teacher_number, m2sbq6_efft, teacher_available, m2sbq3_efft) %>%
  filter(!is.na(m2sbq6_efft) | !is.na(m2sbq3_efft) )


#create indicator for whether each teacher was absent from school
teacher_absence_ex <- teacher_absence_ex %>%
  mutate(sch_absence_rate=100*case_when(
    m2sbq6_efft==6 | teacher_available==2 ~ 1,
    m2sbq6_efft!=6   ~ 0,
    is.na(m2sbq6_efft) ~ as.numeric(NA)))

#create indicator for whether each teacher was absent from classroom or school
teacher_absence_ex <- teacher_absence_ex %>%
  mutate(absence_rate=100*case_when(
    m2sbq6_efft==6 | m2sbq6_efft==5 |  teacher_available==2 ~ 1,
    m2sbq6_efft==1 | m2sbq6_efft==3 | m2sbq6_efft==2 | m2sbq6_efft==4  ~ 0,
    is.na(m2sbq6_efft) ~ as.numeric(NA)) )

#create indicator for whether each principal was absent from school
teacher_absence_ex <- teacher_absence_ex %>%
  mutate(principal_absence=100*case_when(
    m2sbq3_efft==8  ~ 1,
    m2sbq3_efft!=8   ~ 0,
    is.na(m2sbq3_efft) ~ as.numeric(NA))) %>%
  mutate(absence_rate=if_else(is.na(absence_rate), principal_absence, absence_rate ),
         sch_absence_rate=if_else(is.na(sch_absence_rate), principal_absence, sch_absence_rate ),
         presence_rate=100-absence_rate)



```
### Student Attendance

Student attendance is based on the classroom observation of a randomly selected fourth grade class.  The teacher is asked for the class roster and the enumerator then takes a count of the students in the classroom.  A working example is below.

```{r Student_Attendance, eval=FALSE, include=code_inclusion }
#############################################
##### Student Attendance ###########
#############################################

#Percent of 4th grade students who are present during an unannounced visit.

school_data_INPT_ex<- school_dta_anon %>%
  select(m4scq4_inpt, m4scq12_inpt )  %>%
  filter(!is.na(m4scq4_inpt) & !is.na(m4scq12_inpt)) %>%
  mutate(student_attendance=m4scq4_inpt/m4scq12_inpt) %>%
  mutate(student_attendance=100*student_attendance) 
  

label(school_data_INPT_ex$m4scq12_inpt)
```

### Teacher Knowledge


The teacher content knowledge score is based on a teacher assessment given to teachers.  The assessment is described in more detail above.  Math teachers were given a mathematics exam and Language teachers were given a separate language exam.  In cases where a teacher taught both subjects, the teacher is randomly given either the math or language exam. The knowledge score is the sum of the items answered correctly out of the total number of items, based on either the math or language assessment as is given.  A detailed scoring example is omitted, because of space, but details on scoring are provided in the GEPD github repo:

https://github.com/worldbank/GEPD

```{r Teacher_Knowledge, eval=FALSE, include=code_inclusion}
#############################################
##### Teacher Knowledge ###########
#############################################



teacher_assessment_dta_ex <- teacher_assessment_dta_anon %>%
  select(m5sb_tnum, starts_with("m5s1q"), starts_with("m5s2q"))

#calculate teachers lit items correct
teacher_assessment_dta_ex <- teacher_assessment_dta_ex %>%
  mutate(literacy_content_knowledge=100*rowMeans(.[grep(x=colnames(teacher_assessment_dta_ex), pattern="m5s1q")], na.rm=TRUE),
         correct_letter=100*rowMeans(.[grep(x=colnames(teacher_assessment_dta_ex), pattern="m5s1q3")], na.rm=TRUE),
         cloze=100*rowMeans(.[grep(x=colnames(teacher_assessment_dta_ex), pattern="m5s1q2")], na.rm=TRUE),
         grammar=100*rowMeans(.[grep(x=colnames(teacher_assessment_dta_ex), pattern="m5s1q1")], na.rm=TRUE),
         read_passage=100*rowMeans(.[grep(x=colnames(teacher_assessment_dta_ex), pattern="m5s1q4")], na.rm=TRUE))

####Math####
#calculate # of math items
teacher_assessment_dta_ex$math_length<-length(grep(x=colnames(teacher_assessment_dta_ex), pattern="m5s2q"))

math_items<-colnames(teacher_assessment_dta_ex[,grep(x=colnames(teacher_assessment_dta_ex), pattern="m5s2q")])

#calculate teachers math items correct
teacher_assessment_dta_ex <- teacher_assessment_dta_ex %>%
  mutate(math_content_knowledge=100*rowMeans(.[grep(x=colnames(teacher_assessment_dta_ex), pattern="m5s2q")], na.rm=TRUE),
         arithmetic_number_relations=100*rowMeans(.[grep(x=colnames(teacher_assessment_dta_ex), pattern="number")], na.rm=TRUE),
         geometry=100*rowMeans(.[grep(x=colnames(teacher_assessment_dta_ex), pattern="geometric")], na.rm=TRUE),
         interpret_data=100*rowMeans(.[grep(x=colnames(teacher_assessment_dta_ex), pattern="data")], na.rm=TRUE))



```



### 4th Grade Assessment

Students in a randomly chosen class were given an assessment containing math and language items based on the SDI examination. More details on this examination is above.  A students score is the sum of the literacy sub-score and the math sub-score.  The literacy score is constructed so that each literacy item is given the same weight and is the sum of individual literacy items.  Math scores are calculated similarly.  The final content knowledge score is then the sum of the two components.  A detailed scoring example is omitted, because of space, but details on scoring are provided in the GEPD github repo:

Proficiency is then based on whether the student correctly answered a set number of questions (12/13 in literacy, 14/17 in math), which was determined by consulting a set of experts on whether a minimally proficient 4th grader should be able to answer the questions correctly.  

```{r grd4_assess, eval=FALSE, include=code_inclusion}

 ####Literacy####
  #calculate # of literacy items
  #note: grep is a tool for searching text with specified pattern.  In our case, we are looking for m8s1q, which is the prefix of literacy items
  assess_4th_grade_dta$literacy_length<-length(grep(x=colnames(assess_4th_grade_dta), pattern="m8saq"))
  
  lit_items<-colnames(assess_4th_grade_dta[,grep(x=colnames(assess_4th_grade_dta), pattern="m8saq")])
  
  
  #calculate students lit items correct
  assess_4th_grade_dta <- assess_4th_grade_dta %>%
    mutate(literacy_student_knowledge=100*rowMeans(.[grep(x=colnames(assess_4th_grade_dta), pattern="m8saq")], na.rm=TRUE),
           literacy_student_knowledge_nogiraffe=100*rowMeans(.[c('m8saq4_id', 'm8saq5_story', 'm8saq6_story', 'm8saq7_word_choice', 'm8saq2_id', 'm8saq3_id')], na.rm=TRUE))
  
  ####Math####
  #calculate # of math items
  assess_4th_grade_dta$math_length<-length(grep(x=colnames(assess_4th_grade_dta), pattern="m8sbq"))
  
  math_items<-colnames(assess_4th_grade_dta[,grep(x=colnames(assess_4th_grade_dta), pattern="m8sbq")])
  
  
  #calculate students math items correct
  assess_4th_grade_dta <- assess_4th_grade_dta %>%
    mutate(math_student_knowledge=100*rowMeans(.[grep(x=colnames(assess_4th_grade_dta), pattern="m8sbq")], na.rm=TRUE))
  
  ####Total score####
  #calculate students percent correct
  assess_4th_grade_dta <- assess_4th_grade_dta %>%
    mutate(student_knowledge=(math_student_knowledge+literacy_student_knowledge)/2) %>%
    mutate(student_proficient=100*as.numeric(student_knowledge>=82.9), #34/41
           literacy_student_proficient=100*as.numeric(literacy_student_knowledge>=83.3), #20/24 points
           math_student_proficient=100*as.numeric(math_student_knowledge>=82) #14/17 points
)

```


### ECE Assessment

A randomly selected set of three 1st grade students are given an assessment of early literacy, numeracy, executive functioning and socio-emotional skills.  The assessment was created based on items from the MELQO assessment.  A students score is the sum of the literacy sub-score, the math sub-score, the executive functioning score, and the socio-emotional score.  Each domain (literacy, numeracy, executive functioning and socio-emotional skills) is given equal weight.  Within each domain scores are based on the number of items correct in each domain.  


```{r ece, eval=FALSE, include=code_inclusion}

 ####Literacy####
  #calculate # of literacy items
  #note: grep is a tool for searching text with specified pattern.  In our case, we are looking for m8s1q, which is the prefix of literacy items
  
  
  lit_items<-colnames(ecd_dta[,str_detect(
    colnames(ecd_dta), "vocabn|comprehension|letters|words|sentence|nm_writing$|print")])
  
  ecd_dta$literacy_length<-length(lit_items)
  
  #calculate students lit items correct
  ecd_dta <- ecd_dta %>%
    mutate(ecd_literacy_student_knowledge=100*rowMeans(.[grep(x=colnames(ecd_dta), 
                                                              pattern="vocabn|comprehension|letters|words|sentence|nm_writing$|print")], na.rm=TRUE))
  
  ####Math####
  #calculate # of math items
  
  math_items<-colnames(ecd_dta[,str_detect(
    colnames(ecd_dta), "counting|produce_set|number_ident|number_compare|simple_add")])
  
  ecd_dta$math_length<-length(math_items)
  
  
  #calculate students math items correct
  ecd_dta <- ecd_dta %>%
    mutate(ecd_math_student_knowledge=100*rowMeans(.[grep(x=colnames(ecd_dta), 
                                                          pattern="counting|produce_set|number_ident|number_compare|simple_add")], na.rm=TRUE))
  
  ####Executive Functioning####
  #calculate # of Exec Function items
  
  exec_items<-colnames(ecd_dta[,str_detect(
    colnames(ecd_dta), "backward_digit|head_shoulders")])
  
  ecd_dta$exec_length<-length(exec_items)
  
  
  #calculate students excec items correct
  ecd_dta <- ecd_dta %>%
    mutate(ecd_exec_student_knowledge=100*rowMeans(.[grep(x=colnames(ecd_dta), 
                                                          pattern="backward_digit|head_shoulders")], na.rm=TRUE))
  
  ####Socio-Emotional####
  #calculate # of Socio Function items
  
  soc_items<-colnames(ecd_dta[,str_detect(
    colnames(ecd_dta), "perspective$|conflict_resol$")])
  
  ecd_dta$soc_length<-length(soc_items)
  
  
  #calculate students excec items correct
  ecd_dta <- ecd_dta %>%
    mutate(ecd_soc_student_knowledge=100*rowMeans(.[grep(x=colnames(ecd_dta), 
                                                         pattern="perspective$|conflict_resol$")], na.rm=TRUE))
  
  
  ####Total score####
  #calculate students percent correct
  ecd_dta <- ecd_dta %>%
    mutate(ecd_student_knowledge=(ecd_math_student_knowledge+ecd_literacy_student_knowledge+
                                    ecd_exec_student_knowledge + ecd_soc_student_knowledge)/4) %>%
    mutate(ecd_student_proficiency=100*as.numeric(ecd_student_knowledge>=80),
           ecd_math_student_proficiency=100*as.numeric(ecd_math_student_knowledge>=80),
           ecd_literacy_student_proficiency=100*as.numeric(ecd_literacy_student_knowledge>=80),
           ecd_exec_student_proficiency=100*as.numeric(ecd_exec_student_knowledge>=80),
           ecd_soc_student_proficiency=100*as.numeric(ecd_soc_student_knowledge>=80)
    )

```


### School Inputs

  School survey. Total score starts at 1 and points added are the sum of whether a school has:    
  - Functional blackboard     
  - Pens, pencils, textbooks, exercise books    
  - Fraction of students in class with a desk     
  - Used ICT in class and have access to ICT in the school.   
  
```{r inputs, eval=FALSE, include=code_inclusion}
 
  #functioning blackboard and chalk
  school_data_INPT <- school_data_INPT %>%
    mutate(blackboard_functional=case_when(
      m4scq10_inpt==1 & m4scq9_inpt==1 & m4scq8_inpt==1  ~ 1,
      m4scq10_inpt==0 | m4scq9_inpt==0 | m4scq8_inpt==0 ~ 0)) 
  
  #pens, pencils, textbooks, exercise books
  school_data_INPT <- school_data_INPT %>%
    mutate(share_textbook=(m4scq5_inpt)/(m4scq4_inpt)) %>%
    mutate(share_pencil=(m4scq6_inpt)/(m4scq4_inpt)) %>%
    mutate(share_exbook=(m4scq7_inpt)/(m4scq4_inpt)) %>%
    mutate(pens_etc=case_when(
      share_pencil>=0.9 & share_exbook>=0.9  ~ 1,
      share_pencil<0.9 | share_exbook<0.9 ~ 0),
      textbooks=case_when(
        share_textbook>=0.9   ~ 1,
        share_textbook<0.9  ~ 0)) 
  
  #basic classroom furniture
  school_data_INPT <- school_data_INPT %>%
    mutate(share_desk=1-(m4scq11_inpt)/(m4scq4_inpt))
  
  
  #Used ICT 
  school_teacher_questionnaire_INPT <- teacher_questionnaire_INPT %>%
    group_by(school_code) %>%
    summarise(used_ict_pct=mean(m3sbq4_inpt, na.rm=TRUE))
  
  school_data_INPT <- school_data_INPT %>%
    mutate(used_ict_num=case_when(
      m1sbq12_inpt==0  ~ 0,
      (m1sbq12_inpt>=1 ) ~ m1sbq14_inpt,
      (is.na(m1sbq12_inpt==0) | is.na(m1sbq14_inpt)) ~ as.numeric(NA)
    ))
  
  #access to ICT
  school_data_INPT <- school_data_INPT %>%
    mutate(access_ict=case_when(
      m1sbq12_inpt==0 | m1sbq13_inpt==0 ~ 0,
      (m1sbq12_inpt>=1 & m1sbq13_inpt==1 ) ~ 1,
      (m1sbq12_inpt>=1 & m1sbq13_inpt==1 ) ~ 0.5, #Internet didn't work when tested
      (is.na(m1sbq12_inpt==0) | is.na(m1sbq13_inpt) ) ~ as.numeric(NA)
    ))
  
  
  
  inpt_list<-c('blackboard_functional', 'pens_etc', 'textbooks', 'share_desk',  'used_ict', 'access_ict')
  
  final_indicator_data_INPT <- school_data_INPT %>%
    left_join(school_teacher_questionnaire_INPT) %>%
    mutate(used_ict=if_else((used_ict_pct>=0.5 & used_ict_num>=3), 1,0))     %>%  #Set percentage of teachers to use ICT over 50% and number over 3
    group_by(school_code) %>%
    select(preamble_info, inpt_list, contains('INPT')) %>%
    summarise_all(~first(na.omit(.))) %>%
    mutate(n_mssing_INPT=n_miss_row(.)) %>%
    mutate(inputs=textbooks+blackboard_functional + pens_etc + share_desk +  0.5*used_ict + 0.5*access_ict) %>%
    select(preamble_info, inputs, everything()) %>%
    select( -starts_with('interview'), -starts_with('enumerator'))
  
```
  

### School Infrastructure

  School survey. Total score starts at 1 and points added are the sum of whether a school has:    
   - Access to adequate drinking water    
   -Functional toilets.  Extra points available if are separate for boys/girls, private, useable, and have hand washing facilities    
   - Electricity  in the classroom    
   - Internet   
   - School is accessible for those with disabilities (road access, a school ramp for wheelchairs, an entrance wide enough for wheelchairs, ramps to classrooms where needed, accessible toilets, and disability screening for seeing, hearing, and learning disabilities with partial credit for having 1 or 2 or the 3).)
  

```{r infrastructure, eval=FALSE, include=code_inclusion}


  #drinking water
  school_data_INFR <- school_data_INFR %>%
    #
    mutate(drinking_water=if_else((m1sbq9_infr==1 | m1sbq9_infr==2 | m1sbq9_infr==5 | m1sbq9_infr==6), 1,0, as.numeric(NA) ))
  
  #functioning toilets
  school_data_INFR <- school_data_INFR %>%
    mutate(toilet_exists=if_else(m1sbq1_infr==7 ,0,1),
           toilet_separate=if_else((m1sbq2_infr==1 | m1sbq2_infr==3),1,0),
           toilet_private=as.numeric(m1sbq4_infr),
           toilet_usable=as.numeric(m1sbq5_infr),
           toilet_handwashing=as.numeric(m1sbq7_infr),
           toilet_soap=as.numeric(m1sbq8_infr)) %>%
    mutate(functioning_toilet=case_when(
      # exist, separate for boys/girls, clean, private, useable,  handwashing available
      toilet_exists==1 & toilet_usable==1 & toilet_separate==1  & toilet_private==1  & toilet_handwashing==1 ~ 1,
      toilet_exists==0 | toilet_usable==0 | toilet_separate==0  | toilet_private==0  | toilet_handwashing==0 ~ 0
    )) 
  
  #visibility
  school_data_INFR <- school_data_INFR %>%
    left_join(select(school_data_INPT, interview__key, m4scq8_inpt, m4scq9_inpt, m4scq10_inpt, m1sbq15_inpt )) %>%
    mutate(visibility=case_when(
      m4scq10_inpt==1 &  m4scq8_inpt==1  ~ 1,
      m4scq10_inpt==0 & m4scq8_inpt==1 ~ 0)) 
  
  #electricity
  school_data_INFR <- school_data_INFR %>%
    mutate(class_electricity=if_else(m1sbq11_infr==1,1,0)) 
  
  
  #accessibility for people with disabilities
  final_indicator_data_INFR <- school_data_INFR %>%
    group_by(school_code) %>%
    summarise_all(~first(na.omit(.))) %>%
    mutate(
      disab_road_access=bin_var(m1s0q2_infr,1),
      disab_school_ramp=case_when(
        m1s0q3_infr==0 ~ 1,
        (m1s0q4_infr	==1 & m1s0q3_infr	==1) ~ 1,
        (m1s0q4_infr	==0 & m1s0q3_infr	==1) ~ 0,
        is.na(m4scq1_infr) ~ as.numeric(NA)),
      disab_school_entr=bin_var(m1s0q5_infr,1),
      disab_class_ramp=case_when(
        m4scq1_infr==0 ~ 1,
        (m4scq1_infr==1 & m4scq1_infr==1) ~ 1,
        (m4scq1_infr==0 & m4scq1_infr==1) ~ 0,
        is.na(m4scq1_infr) ~ as.numeric(NA)),
      disab_class_entr=bin_var(m4scq3_infr,1),
      disab_screening=rowMeans(select(.,m1sbq17_infr__1,m1sbq17_infr__2,m1sbq17_infr__3), na.rm = TRUE),
      #sum up all components for overall disability accessibility score
      disability_accessibility=(disab_road_access+disab_school_ramp+disab_school_entr+
                                  disab_class_ramp+disab_class_entr+
                                  if_else(m1sbq1_infr==7,0,as.numeric(m1sbq6_infr))+
                                  disab_screening)/7
    ) %>%
    mutate(internet=case_when(
      m1sbq15_inpt==2  ~ 1,
      m1sbq15_inpt==1  ~ 0.5,
      m1sbq15_inpt==0   ~ 0,
      is.na(as.numeric(m1sbq15_inpt)) ~ 0,
      TRUE ~ 0) ) # 1 point if internet working, 0.5 if doesn't work well, 0 if not at all
  
  
  infr_list<-c('drinking_water', 'functioning_toilet', 'internet',  'class_electricity', 'disability_accessibility')
  
  final_indicator_data_INFR <- final_indicator_data_INFR %>%
    mutate(n_mssing_INFR=n_miss_row(.)) %>%
    mutate(infrastructure=(drinking_water+ functioning_toilet+ internet + class_electricity+ disability_accessibility)) %>%
    select(preamble_info, infrastructure, everything()) %>%
    select( -starts_with('interview'), -starts_with('enumerator'))  
  

```

### School Operational Management

Princials/head teachers are given two vignettes:    
  - One on solving the problem of a hypothetical leaky roof     
  - One on solving a problem of inadequate numbers of textbooks.      
  Each vignette is worth 2 points.      
  
  The indicator will measure two things: presence of functions and quality of functions. In each vignette:    
  - 0.5 points are awarded for someone specific having the responsibility to fix    
  - 0.5 point is awarded if the school can fully fund the repair, 0.25 points is awarded if the school must get partial help from the community, and 0 points are awarded if the full cost must be born by the community    
  - 1 point is awarded if the problem is fully resolved in a timely manner, with partial credit given if problem can only be partly resolved.
  
```{r operational_management, eval=FALSE, include=code_inclusion}

```
  
  

## Psychometric Properties of 4th Grade Assessment
For a full report on the psychometric properties of our assessment in Peru, see:

https://worldbankgroup-my.sharepoint.com/:u:/g/personal/bstacy_worldbank_org/EeI0nmjm-MlLl3OyPAfOzdsB0VBT7v-Q1JHrwig3H2FMEw?e=Pq2Fzg

## Psychometric Properties of 1st Grade Assessment
For a full report on the psychometric properties of our assessment in Peru, see:

https://worldbankgroup-my.sharepoint.com/:u:/g/personal/bstacy_worldbank_org/EcwUNOUuTE1Ltjow7o10AUQBulnO_kKRPR0Oh8yTv5l7MA?e=miiiZU


## Psychometric Properties of Teacher Assessment
For a full report on the psychometric properties of our assessment in Peru, see:

https://worldbankgroup-my.sharepoint.com/:u:/g/personal/bstacy_worldbank_org/EbHd7iWaxGhJspphCXLqkfwBAlzQ0hUjtUb8uT151CxL-A?e=82bgKE



